/* automatically generated by rust-bindgen */

#[doc = " The API call returned with no errors. In the case of query calls, this"]
#[doc = " also means that the operation being queried is complete (see"]
#[doc = " ::cudaEventQuery() and ::cudaStreamQuery())."]
pub const cudaError_cudaSuccess: cudaError = 0;
#[doc = " The device function being invoked (usually via ::cudaLaunchKernel()) was not"]
#[doc = " previously configured via the ::cudaConfigureCall() function."]
pub const cudaError_cudaErrorMissingConfiguration: cudaError = 1;
#[doc = " The API call failed because it was unable to allocate enough memory to"]
#[doc = " perform the requested operation."]
pub const cudaError_cudaErrorMemoryAllocation: cudaError = 2;
#[doc = " The API call failed because the CUDA driver and runtime could not be"]
#[doc = " initialized."]
pub const cudaError_cudaErrorInitializationError: cudaError = 3;
#[doc = " An exception occurred on the device while executing a kernel. Common"]
#[doc = " causes include dereferencing an invalid device pointer and accessing"]
#[doc = " out of bounds shared memory. All existing device memory allocations"]
#[doc = " are invalid. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorLaunchFailure: cudaError = 4;
#[doc = " This indicated that a previous kernel launch failed. This was previously"]
#[doc = " used for device emulation of kernel launches."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was"]
#[doc = " removed with the CUDA 3.1 release."]
pub const cudaError_cudaErrorPriorLaunchFailure: cudaError = 5;
#[doc = " This indicates that the device kernel took too long to execute. This can"]
#[doc = " only occur if timeouts are enabled - see the device property"]
#[doc = " \\ref ::cudaDeviceProp::kernelExecTimeoutEnabled \"kernelExecTimeoutEnabled\""]
#[doc = " for more information."]
#[doc = " This leaves the process in an inconsistent state and any further CUDA work"]
#[doc = " will return the same error. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorLaunchTimeout: cudaError = 6;
#[doc = " This indicates that a launch did not occur because it did not have"]
#[doc = " appropriate resources. Although this error is similar to"]
#[doc = " ::cudaErrorInvalidConfiguration, this error usually indicates that the"]
#[doc = " user has attempted to pass too many arguments to the device kernel, or the"]
#[doc = " kernel launch specifies too many threads for the kernel\'s register count."]
pub const cudaError_cudaErrorLaunchOutOfResources: cudaError = 7;
#[doc = " The requested device function does not exist or is not compiled for the"]
#[doc = " proper device architecture."]
pub const cudaError_cudaErrorInvalidDeviceFunction: cudaError = 8;
#[doc = " This indicates that a kernel launch is requesting resources that can"]
#[doc = " never be satisfied by the current device. Requesting more shared memory"]
#[doc = " per block than the device supports will trigger this error, as will"]
#[doc = " requesting too many threads or blocks. See ::cudaDeviceProp for more"]
#[doc = " device limitations."]
pub const cudaError_cudaErrorInvalidConfiguration: cudaError = 9;
#[doc = " This indicates that the device ordinal supplied by the user does not"]
#[doc = " correspond to a valid CUDA device."]
pub const cudaError_cudaErrorInvalidDevice: cudaError = 10;
#[doc = " This indicates that one or more of the parameters passed to the API call"]
#[doc = " is not within an acceptable range of values."]
pub const cudaError_cudaErrorInvalidValue: cudaError = 11;
#[doc = " This indicates that one or more of the pitch-related parameters passed"]
#[doc = " to the API call is not within the acceptable range for pitch."]
pub const cudaError_cudaErrorInvalidPitchValue: cudaError = 12;
#[doc = " This indicates that the symbol name/identifier passed to the API call"]
#[doc = " is not a valid name or identifier."]
pub const cudaError_cudaErrorInvalidSymbol: cudaError = 13;
#[doc = " This indicates that the buffer object could not be mapped."]
pub const cudaError_cudaErrorMapBufferObjectFailed: cudaError = 14;
#[doc = " This indicates that the buffer object could not be unmapped."]
pub const cudaError_cudaErrorUnmapBufferObjectFailed: cudaError = 15;
#[doc = " This indicates that at least one host pointer passed to the API call is"]
#[doc = " not a valid host pointer."]
pub const cudaError_cudaErrorInvalidHostPointer: cudaError = 16;
#[doc = " This indicates that at least one device pointer passed to the API call is"]
#[doc = " not a valid device pointer."]
pub const cudaError_cudaErrorInvalidDevicePointer: cudaError = 17;
#[doc = " This indicates that the texture passed to the API call is not a valid"]
#[doc = " texture."]
pub const cudaError_cudaErrorInvalidTexture: cudaError = 18;
#[doc = " This indicates that the texture binding is not valid. This occurs if you"]
#[doc = " call ::cudaGetTextureAlignmentOffset() with an unbound texture."]
pub const cudaError_cudaErrorInvalidTextureBinding: cudaError = 19;
#[doc = " This indicates that the channel descriptor passed to the API call is not"]
#[doc = " valid. This occurs if the format is not one of the formats specified by"]
#[doc = " ::cudaChannelFormatKind, or if one of the dimensions is invalid."]
pub const cudaError_cudaErrorInvalidChannelDescriptor: cudaError = 20;
#[doc = " This indicates that the direction of the memcpy passed to the API call is"]
#[doc = " not one of the types specified by ::cudaMemcpyKind."]
pub const cudaError_cudaErrorInvalidMemcpyDirection: cudaError = 21;
#[doc = " This indicated that the user has taken the address of a constant variable,"]
#[doc = " which was forbidden up until the CUDA 3.1 release."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 3.1. Variables in constant"]
#[doc = " memory may now have their address taken by the runtime via"]
#[doc = " ::cudaGetSymbolAddress()."]
pub const cudaError_cudaErrorAddressOfConstant: cudaError = 22;
#[doc = " This indicated that a texture fetch was not able to be performed."]
#[doc = " This was previously used for device emulation of texture operations."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was"]
#[doc = " removed with the CUDA 3.1 release."]
pub const cudaError_cudaErrorTextureFetchFailed: cudaError = 23;
#[doc = " This indicated that a texture was not bound for access."]
#[doc = " This was previously used for device emulation of texture operations."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was"]
#[doc = " removed with the CUDA 3.1 release."]
pub const cudaError_cudaErrorTextureNotBound: cudaError = 24;
#[doc = " This indicated that a synchronization operation had failed."]
#[doc = " This was previously used for some device emulation functions."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was"]
#[doc = " removed with the CUDA 3.1 release."]
pub const cudaError_cudaErrorSynchronizationError: cudaError = 25;
#[doc = " This indicates that a non-float texture was being accessed with linear"]
#[doc = " filtering. This is not supported by CUDA."]
pub const cudaError_cudaErrorInvalidFilterSetting: cudaError = 26;
#[doc = " This indicates that an attempt was made to read a non-float texture as a"]
#[doc = " normalized float. This is not supported by CUDA."]
pub const cudaError_cudaErrorInvalidNormSetting: cudaError = 27;
#[doc = " Mixing of device and device emulation code was not allowed."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was"]
#[doc = " removed with the CUDA 3.1 release."]
pub const cudaError_cudaErrorMixedDeviceExecution: cudaError = 28;
#[doc = " This indicates that a CUDA Runtime API call cannot be executed because"]
#[doc = " it is being called during process shut down, at a point in time after"]
#[doc = " CUDA driver has been unloaded."]
pub const cudaError_cudaErrorCudartUnloading: cudaError = 29;
#[doc = " This indicates that an unknown internal error has occurred."]
pub const cudaError_cudaErrorUnknown: cudaError = 30;
#[doc = " This indicates that the API call is not yet implemented. Production"]
#[doc = " releases of CUDA will never return this error."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 4.1."]
pub const cudaError_cudaErrorNotYetImplemented: cudaError = 31;
#[doc = " This indicated that an emulated device pointer exceeded the 32-bit address"]
#[doc = " range."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was"]
#[doc = " removed with the CUDA 3.1 release."]
pub const cudaError_cudaErrorMemoryValueTooLarge: cudaError = 32;
#[doc = " This indicates that a resource handle passed to the API call was not"]
#[doc = " valid. Resource handles are opaque types like ::cudaStream_t and"]
#[doc = " ::cudaEvent_t."]
pub const cudaError_cudaErrorInvalidResourceHandle: cudaError = 33;
#[doc = " This indicates that asynchronous operations issued previously have not"]
#[doc = " completed yet. This result is not actually an error, but must be indicated"]
#[doc = " differently than ::cudaSuccess (which indicates completion). Calls that"]
#[doc = " may return this value include ::cudaEventQuery() and ::cudaStreamQuery()."]
pub const cudaError_cudaErrorNotReady: cudaError = 34;
#[doc = " This indicates that the installed NVIDIA CUDA driver is older than the"]
#[doc = " CUDA runtime library. This is not a supported configuration. Users should"]
#[doc = " install an updated NVIDIA display driver to allow the application to run."]
pub const cudaError_cudaErrorInsufficientDriver: cudaError = 35;
#[doc = " This indicates that the user has called ::cudaSetValidDevices(),"]
#[doc = " ::cudaSetDeviceFlags(), ::cudaD3D9SetDirect3DDevice(),"]
#[doc = " ::cudaD3D10SetDirect3DDevice, ::cudaD3D11SetDirect3DDevice(), or"]
#[doc = " ::cudaVDPAUSetVDPAUDevice() after initializing the CUDA runtime by"]
#[doc = " calling non-device management operations (allocating memory and"]
#[doc = " launching kernels are examples of non-device management operations)."]
#[doc = " This error can also be returned if using runtime/driver"]
#[doc = " interoperability and there is an existing ::CUcontext active on the"]
#[doc = " host thread."]
pub const cudaError_cudaErrorSetOnActiveProcess: cudaError = 36;
#[doc = " This indicates that the surface passed to the API call is not a valid"]
#[doc = " surface."]
pub const cudaError_cudaErrorInvalidSurface: cudaError = 37;
#[doc = " This indicates that no CUDA-capable devices were detected by the installed"]
#[doc = " CUDA driver."]
pub const cudaError_cudaErrorNoDevice: cudaError = 38;
#[doc = " This indicates that an uncorrectable ECC error was detected during"]
#[doc = " execution."]
pub const cudaError_cudaErrorECCUncorrectable: cudaError = 39;
#[doc = " This indicates that a link to a shared object failed to resolve."]
pub const cudaError_cudaErrorSharedObjectSymbolNotFound: cudaError = 40;
#[doc = " This indicates that initialization of a shared object failed."]
pub const cudaError_cudaErrorSharedObjectInitFailed: cudaError = 41;
#[doc = " This indicates that the ::cudaLimit passed to the API call is not"]
#[doc = " supported by the active device."]
pub const cudaError_cudaErrorUnsupportedLimit: cudaError = 42;
#[doc = " This indicates that multiple global or constant variables (across separate"]
#[doc = " CUDA source files in the application) share the same string name."]
pub const cudaError_cudaErrorDuplicateVariableName: cudaError = 43;
#[doc = " This indicates that multiple textures (across separate CUDA source"]
#[doc = " files in the application) share the same string name."]
pub const cudaError_cudaErrorDuplicateTextureName: cudaError = 44;
#[doc = " This indicates that multiple surfaces (across separate CUDA source"]
#[doc = " files in the application) share the same string name."]
pub const cudaError_cudaErrorDuplicateSurfaceName: cudaError = 45;
#[doc = " This indicates that all CUDA devices are busy or unavailable at the current"]
#[doc = " time. Devices are often busy/unavailable due to use of"]
#[doc = " ::cudaComputeModeExclusive, ::cudaComputeModeProhibited or when long"]
#[doc = " running CUDA kernels have filled up the GPU and are blocking new work"]
#[doc = " from starting. They can also be unavailable due to memory constraints"]
#[doc = " on a device that already has active CUDA work being performed."]
pub const cudaError_cudaErrorDevicesUnavailable: cudaError = 46;
#[doc = " This indicates that the device kernel image is invalid."]
pub const cudaError_cudaErrorInvalidKernelImage: cudaError = 47;
#[doc = " This indicates that there is no kernel image available that is suitable"]
#[doc = " for the device. This can occur when a user specifies code generation"]
#[doc = " options for a particular CUDA source file that do not include the"]
#[doc = " corresponding device configuration."]
pub const cudaError_cudaErrorNoKernelImageForDevice: cudaError = 48;
#[doc = " This indicates that the current context is not compatible with this"]
#[doc = " the CUDA Runtime. This can only occur if you are using CUDA"]
#[doc = " Runtime/Driver interoperability and have created an existing Driver"]
#[doc = " context using the driver API. The Driver context may be incompatible"]
#[doc = " either because the Driver context was created using an older version"]
#[doc = " of the API, because the Runtime API call expects a primary driver"]
#[doc = " context and the Driver context is not primary, or because the Driver"]
#[doc = " context has been destroyed. Please see \\ref CUDART_DRIVER \"Interactions"]
#[doc = " with the CUDA Driver API\" for more information."]
pub const cudaError_cudaErrorIncompatibleDriverContext: cudaError = 49;
#[doc = " This error indicates that a call to ::cudaDeviceEnablePeerAccess() is"]
#[doc = " trying to re-enable peer addressing on from a context which has already"]
#[doc = " had peer addressing enabled."]
pub const cudaError_cudaErrorPeerAccessAlreadyEnabled: cudaError = 50;
#[doc = " This error indicates that ::cudaDeviceDisablePeerAccess() is trying to"]
#[doc = " disable peer addressing which has not been enabled yet via"]
#[doc = " ::cudaDeviceEnablePeerAccess()."]
pub const cudaError_cudaErrorPeerAccessNotEnabled: cudaError = 51;
#[doc = " This indicates that a call tried to access an exclusive-thread device that"]
#[doc = " is already in use by a different thread."]
pub const cudaError_cudaErrorDeviceAlreadyInUse: cudaError = 54;
#[doc = " This indicates profiler is not initialized for this run. This can"]
#[doc = " happen when the application is running with external profiling tools"]
#[doc = " like visual profiler."]
pub const cudaError_cudaErrorProfilerDisabled: cudaError = 55;
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 5.0. It is no longer an error"]
#[doc = " to attempt to enable/disable the profiling via ::cudaProfilerStart or"]
#[doc = " ::cudaProfilerStop without initialization."]
pub const cudaError_cudaErrorProfilerNotInitialized: cudaError = 56;
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 5.0. It is no longer an error"]
#[doc = " to call cudaProfilerStart() when profiling is already enabled."]
pub const cudaError_cudaErrorProfilerAlreadyStarted: cudaError = 57;
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 5.0. It is no longer an error"]
#[doc = " to call cudaProfilerStop() when profiling is already disabled."]
pub const cudaError_cudaErrorProfilerAlreadyStopped: cudaError = 58;
#[doc = " An assert triggered in device code during kernel execution. The device"]
#[doc = " cannot be used again. All existing allocations are invalid. To continue"]
#[doc = " using CUDA, the process must be terminated and relaunched."]
pub const cudaError_cudaErrorAssert: cudaError = 59;
#[doc = " This error indicates that the hardware resources required to enable"]
#[doc = " peer access have been exhausted for one or more of the devices"]
#[doc = " passed to ::cudaEnablePeerAccess()."]
pub const cudaError_cudaErrorTooManyPeers: cudaError = 60;
#[doc = " This error indicates that the memory range passed to ::cudaHostRegister()"]
#[doc = " has already been registered."]
pub const cudaError_cudaErrorHostMemoryAlreadyRegistered: cudaError = 61;
#[doc = " This error indicates that the pointer passed to ::cudaHostUnregister()"]
#[doc = " does not correspond to any currently registered memory region."]
pub const cudaError_cudaErrorHostMemoryNotRegistered: cudaError = 62;
#[doc = " This error indicates that an OS call failed."]
pub const cudaError_cudaErrorOperatingSystem: cudaError = 63;
#[doc = " This error indicates that P2P access is not supported across the given"]
#[doc = " devices."]
pub const cudaError_cudaErrorPeerAccessUnsupported: cudaError = 64;
#[doc = " This error indicates that a device runtime grid launch did not occur"]
#[doc = " because the depth of the child grid would exceed the maximum supported"]
#[doc = " number of nested grid launches."]
pub const cudaError_cudaErrorLaunchMaxDepthExceeded: cudaError = 65;
#[doc = " This error indicates that a grid launch did not occur because the kernel"]
#[doc = " uses file-scoped textures which are unsupported by the device runtime."]
#[doc = " Kernels launched via the device runtime only support textures created with"]
#[doc = " the Texture Object API\'s."]
pub const cudaError_cudaErrorLaunchFileScopedTex: cudaError = 66;
#[doc = " This error indicates that a grid launch did not occur because the kernel"]
#[doc = " uses file-scoped surfaces which are unsupported by the device runtime."]
#[doc = " Kernels launched via the device runtime only support surfaces created with"]
#[doc = " the Surface Object API\'s."]
pub const cudaError_cudaErrorLaunchFileScopedSurf: cudaError = 67;
#[doc = " This error indicates that a call to ::cudaDeviceSynchronize made from"]
#[doc = " the device runtime failed because the call was made at grid depth greater"]
#[doc = " than than either the default (2 levels of grids) or user specified device"]
#[doc = " limit ::cudaLimitDevRuntimeSyncDepth. To be able to synchronize on"]
#[doc = " launched grids at a greater depth successfully, the maximum nested"]
#[doc = " depth at which ::cudaDeviceSynchronize will be called must be specified"]
#[doc = " with the ::cudaLimitDevRuntimeSyncDepth limit to the ::cudaDeviceSetLimit"]
#[doc = " api before the host-side launch of a kernel using the device runtime."]
#[doc = " Keep in mind that additional levels of sync depth require the runtime"]
#[doc = " to reserve large amounts of device memory that cannot be used for"]
#[doc = " user allocations."]
pub const cudaError_cudaErrorSyncDepthExceeded: cudaError = 68;
#[doc = " This error indicates that a device runtime grid launch failed because"]
#[doc = " the launch would exceed the limit ::cudaLimitDevRuntimePendingLaunchCount."]
#[doc = " For this launch to proceed successfully, ::cudaDeviceSetLimit must be"]
#[doc = " called to set the ::cudaLimitDevRuntimePendingLaunchCount to be higher"]
#[doc = " than the upper bound of outstanding launches that can be issued to the"]
#[doc = " device runtime. Keep in mind that raising the limit of pending device"]
#[doc = " runtime launches will require the runtime to reserve device memory that"]
#[doc = " cannot be used for user allocations."]
pub const cudaError_cudaErrorLaunchPendingCountExceeded: cudaError = 69;
#[doc = " This error indicates the attempted operation is not permitted."]
pub const cudaError_cudaErrorNotPermitted: cudaError = 70;
#[doc = " This error indicates the attempted operation is not supported"]
#[doc = " on the current system or device."]
pub const cudaError_cudaErrorNotSupported: cudaError = 71;
#[doc = " Device encountered an error in the call stack during kernel execution,"]
#[doc = " possibly due to stack corruption or exceeding the stack size limit."]
#[doc = " This leaves the process in an inconsistent state and any further CUDA work"]
#[doc = " will return the same error. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorHardwareStackError: cudaError = 72;
#[doc = " The device encountered an illegal instruction during kernel execution"]
#[doc = " This leaves the process in an inconsistent state and any further CUDA work"]
#[doc = " will return the same error. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorIllegalInstruction: cudaError = 73;
#[doc = " The device encountered a load or store instruction"]
#[doc = " on a memory address which is not aligned."]
#[doc = " This leaves the process in an inconsistent state and any further CUDA work"]
#[doc = " will return the same error. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorMisalignedAddress: cudaError = 74;
#[doc = " While executing a kernel, the device encountered an instruction"]
#[doc = " which can only operate on memory locations in certain address spaces"]
#[doc = " (global, shared, or local), but was supplied a memory address not"]
#[doc = " belonging to an allowed address space."]
#[doc = " This leaves the process in an inconsistent state and any further CUDA work"]
#[doc = " will return the same error. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorInvalidAddressSpace: cudaError = 75;
#[doc = " The device encountered an invalid program counter."]
#[doc = " This leaves the process in an inconsistent state and any further CUDA work"]
#[doc = " will return the same error. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorInvalidPc: cudaError = 76;
#[doc = " The device encountered a load or store instruction on an invalid memory address."]
#[doc = " This leaves the process in an inconsistent state and any further CUDA work"]
#[doc = " will return the same error. To continue using CUDA, the process must be terminated"]
#[doc = " and relaunched."]
pub const cudaError_cudaErrorIllegalAddress: cudaError = 77;
#[doc = " A PTX compilation failed. The runtime may fall back to compiling PTX if"]
#[doc = " an application does not contain a suitable binary for the current device."]
pub const cudaError_cudaErrorInvalidPtx: cudaError = 78;
#[doc = " This indicates an error with the OpenGL or DirectX context."]
pub const cudaError_cudaErrorInvalidGraphicsContext: cudaError = 79;
#[doc = " This indicates that an uncorrectable NVLink error was detected during the"]
#[doc = " execution."]
pub const cudaError_cudaErrorNvlinkUncorrectable: cudaError = 80;
#[doc = " This indicates that the PTX JIT compiler library was not found. The JIT Compiler"]
#[doc = " library is used for PTX compilation. The runtime may fall back to compiling PTX"]
#[doc = " if an application does not contain a suitable binary for the current device."]
pub const cudaError_cudaErrorJitCompilerNotFound: cudaError = 81;
#[doc = " This error indicates that the number of blocks launched per grid for a kernel that was"]
#[doc = " launched via either ::cudaLaunchCooperativeKernel or ::cudaLaunchCooperativeKernelMultiDevice"]
#[doc = " exceeds the maximum number of blocks as allowed by ::cudaOccupancyMaxActiveBlocksPerMultiprocessor"]
#[doc = " or ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags times the number of multiprocessors"]
#[doc = " as specified by the device attribute ::cudaDevAttrMultiProcessorCount."]
pub const cudaError_cudaErrorCooperativeLaunchTooLarge: cudaError = 82;
#[doc = " This error indicates that the system is not yet ready to start any CUDA"]
#[doc = " work.  To continue using CUDA, verify the system configuration is in a"]
#[doc = " valid state and all required driver daemons are actively running."]
pub const cudaError_cudaErrorSystemNotReady: cudaError = 83;
#[doc = " This indicates that a resource required by the API call is not in a"]
#[doc = " valid state to perform the requested operation."]
pub const cudaError_cudaErrorIllegalState: cudaError = 84;
#[doc = " This indicates an internal startup failure in the CUDA runtime."]
pub const cudaError_cudaErrorStartupFailure: cudaError = 127;
#[doc = " The operation is not permitted when the stream is capturing."]
pub const cudaError_cudaErrorStreamCaptureUnsupported: cudaError = 900;
#[doc = " The current capture sequence on the stream has been invalidated due to"]
#[doc = " a previous error."]
pub const cudaError_cudaErrorStreamCaptureInvalidated: cudaError = 901;
#[doc = " The operation would have resulted in a merge of two independent capture"]
#[doc = " sequences."]
pub const cudaError_cudaErrorStreamCaptureMerge: cudaError = 902;
#[doc = " The capture was not initiated in this stream."]
pub const cudaError_cudaErrorStreamCaptureUnmatched: cudaError = 903;
#[doc = " The capture sequence contains a fork that was not joined to the primary"]
#[doc = " stream."]
pub const cudaError_cudaErrorStreamCaptureUnjoined: cudaError = 904;
#[doc = " A dependency would have been created which crosses the capture sequence"]
#[doc = " boundary. Only implicit in-stream ordering dependencies are allowed to"]
#[doc = " cross the boundary."]
pub const cudaError_cudaErrorStreamCaptureIsolation: cudaError = 905;
#[doc = " The operation would have resulted in a disallowed implicit dependency on"]
#[doc = " a current capture sequence from cudaStreamLegacy."]
pub const cudaError_cudaErrorStreamCaptureImplicit: cudaError = 906;
#[doc = " The operation is not permitted on an event which was last recorded in a"]
#[doc = " capturing stream."]
pub const cudaError_cudaErrorCapturedEvent: cudaError = 907;
#[doc = " Any unhandled CUDA driver error is added to this value and returned via"]
#[doc = " the runtime. Production releases of CUDA should not return such errors."]
#[doc = " \\deprecated"]
#[doc = " This error return is deprecated as of CUDA 4.1."]
pub const cudaError_cudaErrorApiFailureBase: cudaError = 10000;
#[doc = " CUDA error types"]
pub type cudaError = u32;
#[doc = "< Host   -> Host"]
pub const cudaMemcpyKind_cudaMemcpyHostToHost: cudaMemcpyKind = 0;
#[doc = "< Host   -> Device"]
pub const cudaMemcpyKind_cudaMemcpyHostToDevice: cudaMemcpyKind = 1;
#[doc = "< Device -> Host"]
pub const cudaMemcpyKind_cudaMemcpyDeviceToHost: cudaMemcpyKind = 2;
#[doc = "< Device -> Device"]
pub const cudaMemcpyKind_cudaMemcpyDeviceToDevice: cudaMemcpyKind = 3;
#[doc = "< Direction of the transfer is inferred from the pointer values. Requires unified virtual addressing"]
pub const cudaMemcpyKind_cudaMemcpyDefault: cudaMemcpyKind = 4;
#[doc = " CUDA memory copy types"]
pub type cudaMemcpyKind = u32;
#[doc = " CUDA graphics interop resource"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct cudaGraphicsResource {
    _unused: [u8; 0],
}
#[doc = "< Data will mostly be read and only occassionally be written to"]
pub const cudaMemoryAdvise_cudaMemAdviseSetReadMostly: cudaMemoryAdvise = 1;
#[doc = "< Undo the effect of ::cudaMemAdviseSetReadMostly"]
pub const cudaMemoryAdvise_cudaMemAdviseUnsetReadMostly: cudaMemoryAdvise = 2;
#[doc = "< Set the preferred location for the data as the specified device"]
pub const cudaMemoryAdvise_cudaMemAdviseSetPreferredLocation: cudaMemoryAdvise = 3;
#[doc = "< Clear the preferred location for the data"]
pub const cudaMemoryAdvise_cudaMemAdviseUnsetPreferredLocation: cudaMemoryAdvise = 4;
#[doc = "< Data will be accessed by the specified device, so prevent page faults as much as possible"]
pub const cudaMemoryAdvise_cudaMemAdviseSetAccessedBy: cudaMemoryAdvise = 5;
#[doc = "< Let the Unified Memory subsystem decide on the page faulting policy for the specified device"]
pub const cudaMemoryAdvise_cudaMemAdviseUnsetAccessedBy: cudaMemoryAdvise = 6;
#[doc = " CUDA Memory Advise values"]
pub type cudaMemoryAdvise = u32;
#[doc = "< Whether the range will mostly be read and only occassionally be written to"]
pub const cudaMemRangeAttribute_cudaMemRangeAttributeReadMostly: cudaMemRangeAttribute = 1;
#[doc = "< The preferred location of the range"]
pub const cudaMemRangeAttribute_cudaMemRangeAttributePreferredLocation: cudaMemRangeAttribute = 2;
#[doc = "< Memory range has ::cudaMemAdviseSetAccessedBy set for specified device"]
pub const cudaMemRangeAttribute_cudaMemRangeAttributeAccessedBy: cudaMemRangeAttribute = 3;
#[doc = "< The last location to which the range was prefetched"]
pub const cudaMemRangeAttribute_cudaMemRangeAttributeLastPrefetchLocation: cudaMemRangeAttribute =
    4;
#[doc = " CUDA range attributes"]
pub type cudaMemRangeAttribute = u32;
#[doc = "< Maximum number of threads per block"]
pub const cudaDeviceAttr_cudaDevAttrMaxThreadsPerBlock: cudaDeviceAttr = 1;
#[doc = "< Maximum block dimension X"]
pub const cudaDeviceAttr_cudaDevAttrMaxBlockDimX: cudaDeviceAttr = 2;
#[doc = "< Maximum block dimension Y"]
pub const cudaDeviceAttr_cudaDevAttrMaxBlockDimY: cudaDeviceAttr = 3;
#[doc = "< Maximum block dimension Z"]
pub const cudaDeviceAttr_cudaDevAttrMaxBlockDimZ: cudaDeviceAttr = 4;
#[doc = "< Maximum grid dimension X"]
pub const cudaDeviceAttr_cudaDevAttrMaxGridDimX: cudaDeviceAttr = 5;
#[doc = "< Maximum grid dimension Y"]
pub const cudaDeviceAttr_cudaDevAttrMaxGridDimY: cudaDeviceAttr = 6;
#[doc = "< Maximum grid dimension Z"]
pub const cudaDeviceAttr_cudaDevAttrMaxGridDimZ: cudaDeviceAttr = 7;
#[doc = "< Maximum shared memory available per block in bytes"]
pub const cudaDeviceAttr_cudaDevAttrMaxSharedMemoryPerBlock: cudaDeviceAttr = 8;
#[doc = "< Memory available on device for __constant__ variables in a CUDA C kernel in bytes"]
pub const cudaDeviceAttr_cudaDevAttrTotalConstantMemory: cudaDeviceAttr = 9;
#[doc = "< Warp size in threads"]
pub const cudaDeviceAttr_cudaDevAttrWarpSize: cudaDeviceAttr = 10;
#[doc = "< Maximum pitch in bytes allowed by memory copies"]
pub const cudaDeviceAttr_cudaDevAttrMaxPitch: cudaDeviceAttr = 11;
#[doc = "< Maximum number of 32-bit registers available per block"]
pub const cudaDeviceAttr_cudaDevAttrMaxRegistersPerBlock: cudaDeviceAttr = 12;
#[doc = "< Peak clock frequency in kilohertz"]
pub const cudaDeviceAttr_cudaDevAttrClockRate: cudaDeviceAttr = 13;
#[doc = "< Alignment requirement for textures"]
pub const cudaDeviceAttr_cudaDevAttrTextureAlignment: cudaDeviceAttr = 14;
#[doc = "< Device can possibly copy memory and execute a kernel concurrently"]
pub const cudaDeviceAttr_cudaDevAttrGpuOverlap: cudaDeviceAttr = 15;
#[doc = "< Number of multiprocessors on device"]
pub const cudaDeviceAttr_cudaDevAttrMultiProcessorCount: cudaDeviceAttr = 16;
#[doc = "< Specifies whether there is a run time limit on kernels"]
pub const cudaDeviceAttr_cudaDevAttrKernelExecTimeout: cudaDeviceAttr = 17;
#[doc = "< Device is integrated with host memory"]
pub const cudaDeviceAttr_cudaDevAttrIntegrated: cudaDeviceAttr = 18;
#[doc = "< Device can map host memory into CUDA address space"]
pub const cudaDeviceAttr_cudaDevAttrCanMapHostMemory: cudaDeviceAttr = 19;
#[doc = "< Compute mode (See ::cudaComputeMode for details)"]
pub const cudaDeviceAttr_cudaDevAttrComputeMode: cudaDeviceAttr = 20;
#[doc = "< Maximum 1D texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DWidth: cudaDeviceAttr = 21;
#[doc = "< Maximum 2D texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DWidth: cudaDeviceAttr = 22;
#[doc = "< Maximum 2D texture height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DHeight: cudaDeviceAttr = 23;
#[doc = "< Maximum 3D texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DWidth: cudaDeviceAttr = 24;
#[doc = "< Maximum 3D texture height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DHeight: cudaDeviceAttr = 25;
#[doc = "< Maximum 3D texture depth"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DDepth: cudaDeviceAttr = 26;
#[doc = "< Maximum 2D layered texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLayeredWidth: cudaDeviceAttr = 27;
#[doc = "< Maximum 2D layered texture height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLayeredHeight: cudaDeviceAttr = 28;
#[doc = "< Maximum layers in a 2D layered texture"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLayeredLayers: cudaDeviceAttr = 29;
#[doc = "< Alignment requirement for surfaces"]
pub const cudaDeviceAttr_cudaDevAttrSurfaceAlignment: cudaDeviceAttr = 30;
#[doc = "< Device can possibly execute multiple kernels concurrently"]
pub const cudaDeviceAttr_cudaDevAttrConcurrentKernels: cudaDeviceAttr = 31;
#[doc = "< Device has ECC support enabled"]
pub const cudaDeviceAttr_cudaDevAttrEccEnabled: cudaDeviceAttr = 32;
#[doc = "< PCI bus ID of the device"]
pub const cudaDeviceAttr_cudaDevAttrPciBusId: cudaDeviceAttr = 33;
#[doc = "< PCI device ID of the device"]
pub const cudaDeviceAttr_cudaDevAttrPciDeviceId: cudaDeviceAttr = 34;
#[doc = "< Device is using TCC driver model"]
pub const cudaDeviceAttr_cudaDevAttrTccDriver: cudaDeviceAttr = 35;
#[doc = "< Peak memory clock frequency in kilohertz"]
pub const cudaDeviceAttr_cudaDevAttrMemoryClockRate: cudaDeviceAttr = 36;
#[doc = "< Global memory bus width in bits"]
pub const cudaDeviceAttr_cudaDevAttrGlobalMemoryBusWidth: cudaDeviceAttr = 37;
#[doc = "< Size of L2 cache in bytes"]
pub const cudaDeviceAttr_cudaDevAttrL2CacheSize: cudaDeviceAttr = 38;
#[doc = "< Maximum resident threads per multiprocessor"]
pub const cudaDeviceAttr_cudaDevAttrMaxThreadsPerMultiProcessor: cudaDeviceAttr = 39;
#[doc = "< Number of asynchronous engines"]
pub const cudaDeviceAttr_cudaDevAttrAsyncEngineCount: cudaDeviceAttr = 40;
#[doc = "< Device shares a unified address space with the host"]
pub const cudaDeviceAttr_cudaDevAttrUnifiedAddressing: cudaDeviceAttr = 41;
#[doc = "< Maximum 1D layered texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DLayeredWidth: cudaDeviceAttr = 42;
#[doc = "< Maximum layers in a 1D layered texture"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DLayeredLayers: cudaDeviceAttr = 43;
#[doc = "< Maximum 2D texture width if cudaArrayTextureGather is set"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DGatherWidth: cudaDeviceAttr = 45;
#[doc = "< Maximum 2D texture height if cudaArrayTextureGather is set"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DGatherHeight: cudaDeviceAttr = 46;
#[doc = "< Alternate maximum 3D texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DWidthAlt: cudaDeviceAttr = 47;
#[doc = "< Alternate maximum 3D texture height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DHeightAlt: cudaDeviceAttr = 48;
#[doc = "< Alternate maximum 3D texture depth"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DDepthAlt: cudaDeviceAttr = 49;
#[doc = "< PCI domain ID of the device"]
pub const cudaDeviceAttr_cudaDevAttrPciDomainId: cudaDeviceAttr = 50;
#[doc = "< Pitch alignment requirement for textures"]
pub const cudaDeviceAttr_cudaDevAttrTexturePitchAlignment: cudaDeviceAttr = 51;
#[doc = "< Maximum cubemap texture width/height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTextureCubemapWidth: cudaDeviceAttr = 52;
#[doc = "< Maximum cubemap layered texture width/height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTextureCubemapLayeredWidth: cudaDeviceAttr = 53;
#[doc = "< Maximum layers in a cubemap layered texture"]
pub const cudaDeviceAttr_cudaDevAttrMaxTextureCubemapLayeredLayers: cudaDeviceAttr = 54;
#[doc = "< Maximum 1D surface width"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface1DWidth: cudaDeviceAttr = 55;
#[doc = "< Maximum 2D surface width"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DWidth: cudaDeviceAttr = 56;
#[doc = "< Maximum 2D surface height"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DHeight: cudaDeviceAttr = 57;
#[doc = "< Maximum 3D surface width"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface3DWidth: cudaDeviceAttr = 58;
#[doc = "< Maximum 3D surface height"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface3DHeight: cudaDeviceAttr = 59;
#[doc = "< Maximum 3D surface depth"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface3DDepth: cudaDeviceAttr = 60;
#[doc = "< Maximum 1D layered surface width"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface1DLayeredWidth: cudaDeviceAttr = 61;
#[doc = "< Maximum layers in a 1D layered surface"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface1DLayeredLayers: cudaDeviceAttr = 62;
#[doc = "< Maximum 2D layered surface width"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DLayeredWidth: cudaDeviceAttr = 63;
#[doc = "< Maximum 2D layered surface height"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DLayeredHeight: cudaDeviceAttr = 64;
#[doc = "< Maximum layers in a 2D layered surface"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DLayeredLayers: cudaDeviceAttr = 65;
#[doc = "< Maximum cubemap surface width"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurfaceCubemapWidth: cudaDeviceAttr = 66;
#[doc = "< Maximum cubemap layered surface width"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurfaceCubemapLayeredWidth: cudaDeviceAttr = 67;
#[doc = "< Maximum layers in a cubemap layered surface"]
pub const cudaDeviceAttr_cudaDevAttrMaxSurfaceCubemapLayeredLayers: cudaDeviceAttr = 68;
#[doc = "< Maximum 1D linear texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DLinearWidth: cudaDeviceAttr = 69;
#[doc = "< Maximum 2D linear texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLinearWidth: cudaDeviceAttr = 70;
#[doc = "< Maximum 2D linear texture height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLinearHeight: cudaDeviceAttr = 71;
#[doc = "< Maximum 2D linear texture pitch in bytes"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLinearPitch: cudaDeviceAttr = 72;
#[doc = "< Maximum mipmapped 2D texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DMipmappedWidth: cudaDeviceAttr = 73;
#[doc = "< Maximum mipmapped 2D texture height"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DMipmappedHeight: cudaDeviceAttr = 74;
#[doc = "< Major compute capability version number"]
pub const cudaDeviceAttr_cudaDevAttrComputeCapabilityMajor: cudaDeviceAttr = 75;
#[doc = "< Minor compute capability version number"]
pub const cudaDeviceAttr_cudaDevAttrComputeCapabilityMinor: cudaDeviceAttr = 76;
#[doc = "< Maximum mipmapped 1D texture width"]
pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DMipmappedWidth: cudaDeviceAttr = 77;
#[doc = "< Device supports stream priorities"]
pub const cudaDeviceAttr_cudaDevAttrStreamPrioritiesSupported: cudaDeviceAttr = 78;
#[doc = "< Device supports caching globals in L1"]
pub const cudaDeviceAttr_cudaDevAttrGlobalL1CacheSupported: cudaDeviceAttr = 79;
#[doc = "< Device supports caching locals in L1"]
pub const cudaDeviceAttr_cudaDevAttrLocalL1CacheSupported: cudaDeviceAttr = 80;
#[doc = "< Maximum shared memory available per multiprocessor in bytes"]
pub const cudaDeviceAttr_cudaDevAttrMaxSharedMemoryPerMultiprocessor: cudaDeviceAttr = 81;
#[doc = "< Maximum number of 32-bit registers available per multiprocessor"]
pub const cudaDeviceAttr_cudaDevAttrMaxRegistersPerMultiprocessor: cudaDeviceAttr = 82;
#[doc = "< Device can allocate managed memory on this system"]
pub const cudaDeviceAttr_cudaDevAttrManagedMemory: cudaDeviceAttr = 83;
#[doc = "< Device is on a multi-GPU board"]
pub const cudaDeviceAttr_cudaDevAttrIsMultiGpuBoard: cudaDeviceAttr = 84;
#[doc = "< Unique identifier for a group of devices on the same multi-GPU board"]
pub const cudaDeviceAttr_cudaDevAttrMultiGpuBoardGroupID: cudaDeviceAttr = 85;
#[doc = "< Link between the device and the host supports native atomic operations"]
pub const cudaDeviceAttr_cudaDevAttrHostNativeAtomicSupported: cudaDeviceAttr = 86;
#[doc = "< Ratio of single precision performance (in floating-point operations per second) to double precision performance"]
pub const cudaDeviceAttr_cudaDevAttrSingleToDoublePrecisionPerfRatio: cudaDeviceAttr = 87;
#[doc = "< Device supports coherently accessing pageable memory without calling cudaHostRegister on it"]
pub const cudaDeviceAttr_cudaDevAttrPageableMemoryAccess: cudaDeviceAttr = 88;
#[doc = "< Device can coherently access managed memory concurrently with the CPU"]
pub const cudaDeviceAttr_cudaDevAttrConcurrentManagedAccess: cudaDeviceAttr = 89;
#[doc = "< Device supports Compute Preemption"]
pub const cudaDeviceAttr_cudaDevAttrComputePreemptionSupported: cudaDeviceAttr = 90;
#[doc = "< Device can access host registered memory at the same virtual address as the CPU"]
pub const cudaDeviceAttr_cudaDevAttrCanUseHostPointerForRegisteredMem: cudaDeviceAttr = 91;
pub const cudaDeviceAttr_cudaDevAttrReserved92: cudaDeviceAttr = 92;
pub const cudaDeviceAttr_cudaDevAttrReserved93: cudaDeviceAttr = 93;
pub const cudaDeviceAttr_cudaDevAttrReserved94: cudaDeviceAttr = 94;
#[doc = "< Device supports launching cooperative kernels via ::cudaLaunchCooperativeKernel"]
pub const cudaDeviceAttr_cudaDevAttrCooperativeLaunch: cudaDeviceAttr = 95;
#[doc = "< Device can participate in cooperative kernels launched via ::cudaLaunchCooperativeKernelMultiDevice"]
pub const cudaDeviceAttr_cudaDevAttrCooperativeMultiDeviceLaunch: cudaDeviceAttr = 96;
#[doc = "< The maximum optin shared memory per block. This value may vary by chip. See ::cudaFuncSetAttribute"]
pub const cudaDeviceAttr_cudaDevAttrMaxSharedMemoryPerBlockOptin: cudaDeviceAttr = 97;
#[doc = "< Device supports flushing of outstanding remote writes."]
pub const cudaDeviceAttr_cudaDevAttrCanFlushRemoteWrites: cudaDeviceAttr = 98;
#[doc = "< Device supports host memory registration via ::cudaHostRegister."]
pub const cudaDeviceAttr_cudaDevAttrHostRegisterSupported: cudaDeviceAttr = 99;
#[doc = "< Device accesses pageable memory via the host\'s page tables."]
pub const cudaDeviceAttr_cudaDevAttrPageableMemoryAccessUsesHostPageTables: cudaDeviceAttr = 100;
#[doc = "< Host can directly access managed memory on the device without migration."]
pub const cudaDeviceAttr_cudaDevAttrDirectManagedMemAccessFromHost: cudaDeviceAttr = 101;
#[doc = " CUDA device attributes"]
pub type cudaDeviceAttr = u32;
pub type cudaUUID_t = CUuuid_st;
#[doc = " CUDA device properties"]
#[repr(C)]
pub struct cudaDeviceProp {
    #[doc = "< ASCII string identifying device"]
    pub name: [::std::os::raw::c_char; 256usize],
    #[doc = "< 16-byte unique identifier"]
    pub uuid: cudaUUID_t,
    #[doc = "< 8-byte locally unique identifier. Value is undefined on TCC and non-Windows platforms"]
    pub luid: [::std::os::raw::c_char; 8usize],
    #[doc = "< LUID device node mask. Value is undefined on TCC and non-Windows platforms"]
    pub luidDeviceNodeMask: ::std::os::raw::c_uint,
    #[doc = "< Global memory available on device in bytes"]
    pub totalGlobalMem: usize,
    #[doc = "< Shared memory available per block in bytes"]
    pub sharedMemPerBlock: usize,
    #[doc = "< 32-bit registers available per block"]
    pub regsPerBlock: ::std::os::raw::c_int,
    #[doc = "< Warp size in threads"]
    pub warpSize: ::std::os::raw::c_int,
    #[doc = "< Maximum pitch in bytes allowed by memory copies"]
    pub memPitch: usize,
    #[doc = "< Maximum number of threads per block"]
    pub maxThreadsPerBlock: ::std::os::raw::c_int,
    #[doc = "< Maximum size of each dimension of a block"]
    pub maxThreadsDim: [::std::os::raw::c_int; 3usize],
    #[doc = "< Maximum size of each dimension of a grid"]
    pub maxGridSize: [::std::os::raw::c_int; 3usize],
    #[doc = "< Clock frequency in kilohertz"]
    pub clockRate: ::std::os::raw::c_int,
    #[doc = "< Constant memory available on device in bytes"]
    pub totalConstMem: usize,
    #[doc = "< Major compute capability"]
    pub major: ::std::os::raw::c_int,
    #[doc = "< Minor compute capability"]
    pub minor: ::std::os::raw::c_int,
    #[doc = "< Alignment requirement for textures"]
    pub textureAlignment: usize,
    #[doc = "< Pitch alignment requirement for texture references bound to pitched memory"]
    pub texturePitchAlignment: usize,
    #[doc = "< Device can concurrently copy memory and execute a kernel. Deprecated. Use instead asyncEngineCount."]
    pub deviceOverlap: ::std::os::raw::c_int,
    #[doc = "< Number of multiprocessors on device"]
    pub multiProcessorCount: ::std::os::raw::c_int,
    #[doc = "< Specified whether there is a run time limit on kernels"]
    pub kernelExecTimeoutEnabled: ::std::os::raw::c_int,
    #[doc = "< Device is integrated as opposed to discrete"]
    pub integrated: ::std::os::raw::c_int,
    #[doc = "< Device can map host memory with cudaHostAlloc/cudaHostGetDevicePointer"]
    pub canMapHostMemory: ::std::os::raw::c_int,
    #[doc = "< Compute mode (See ::cudaComputeMode)"]
    pub computeMode: ::std::os::raw::c_int,
    #[doc = "< Maximum 1D texture size"]
    pub maxTexture1D: ::std::os::raw::c_int,
    #[doc = "< Maximum 1D mipmapped texture size"]
    pub maxTexture1DMipmap: ::std::os::raw::c_int,
    #[doc = "< Maximum size for 1D textures bound to linear memory"]
    pub maxTexture1DLinear: ::std::os::raw::c_int,
    #[doc = "< Maximum 2D texture dimensions"]
    pub maxTexture2D: [::std::os::raw::c_int; 2usize],
    #[doc = "< Maximum 2D mipmapped texture dimensions"]
    pub maxTexture2DMipmap: [::std::os::raw::c_int; 2usize],
    #[doc = "< Maximum dimensions (width, height, pitch) for 2D textures bound to pitched memory"]
    pub maxTexture2DLinear: [::std::os::raw::c_int; 3usize],
    #[doc = "< Maximum 2D texture dimensions if texture gather operations have to be performed"]
    pub maxTexture2DGather: [::std::os::raw::c_int; 2usize],
    #[doc = "< Maximum 3D texture dimensions"]
    pub maxTexture3D: [::std::os::raw::c_int; 3usize],
    #[doc = "< Maximum alternate 3D texture dimensions"]
    pub maxTexture3DAlt: [::std::os::raw::c_int; 3usize],
    #[doc = "< Maximum Cubemap texture dimensions"]
    pub maxTextureCubemap: ::std::os::raw::c_int,
    #[doc = "< Maximum 1D layered texture dimensions"]
    pub maxTexture1DLayered: [::std::os::raw::c_int; 2usize],
    #[doc = "< Maximum 2D layered texture dimensions"]
    pub maxTexture2DLayered: [::std::os::raw::c_int; 3usize],
    #[doc = "< Maximum Cubemap layered texture dimensions"]
    pub maxTextureCubemapLayered: [::std::os::raw::c_int; 2usize],
    #[doc = "< Maximum 1D surface size"]
    pub maxSurface1D: ::std::os::raw::c_int,
    #[doc = "< Maximum 2D surface dimensions"]
    pub maxSurface2D: [::std::os::raw::c_int; 2usize],
    #[doc = "< Maximum 3D surface dimensions"]
    pub maxSurface3D: [::std::os::raw::c_int; 3usize],
    #[doc = "< Maximum 1D layered surface dimensions"]
    pub maxSurface1DLayered: [::std::os::raw::c_int; 2usize],
    #[doc = "< Maximum 2D layered surface dimensions"]
    pub maxSurface2DLayered: [::std::os::raw::c_int; 3usize],
    #[doc = "< Maximum Cubemap surface dimensions"]
    pub maxSurfaceCubemap: ::std::os::raw::c_int,
    #[doc = "< Maximum Cubemap layered surface dimensions"]
    pub maxSurfaceCubemapLayered: [::std::os::raw::c_int; 2usize],
    #[doc = "< Alignment requirements for surfaces"]
    pub surfaceAlignment: usize,
    #[doc = "< Device can possibly execute multiple kernels concurrently"]
    pub concurrentKernels: ::std::os::raw::c_int,
    #[doc = "< Device has ECC support enabled"]
    pub ECCEnabled: ::std::os::raw::c_int,
    #[doc = "< PCI bus ID of the device"]
    pub pciBusID: ::std::os::raw::c_int,
    #[doc = "< PCI device ID of the device"]
    pub pciDeviceID: ::std::os::raw::c_int,
    #[doc = "< PCI domain ID of the device"]
    pub pciDomainID: ::std::os::raw::c_int,
    #[doc = "< 1 if device is a Tesla device using TCC driver, 0 otherwise"]
    pub tccDriver: ::std::os::raw::c_int,
    #[doc = "< Number of asynchronous engines"]
    pub asyncEngineCount: ::std::os::raw::c_int,
    #[doc = "< Device shares a unified address space with the host"]
    pub unifiedAddressing: ::std::os::raw::c_int,
    #[doc = "< Peak memory clock frequency in kilohertz"]
    pub memoryClockRate: ::std::os::raw::c_int,
    #[doc = "< Global memory bus width in bits"]
    pub memoryBusWidth: ::std::os::raw::c_int,
    #[doc = "< Size of L2 cache in bytes"]
    pub l2CacheSize: ::std::os::raw::c_int,
    #[doc = "< Maximum resident threads per multiprocessor"]
    pub maxThreadsPerMultiProcessor: ::std::os::raw::c_int,
    #[doc = "< Device supports stream priorities"]
    pub streamPrioritiesSupported: ::std::os::raw::c_int,
    #[doc = "< Device supports caching globals in L1"]
    pub globalL1CacheSupported: ::std::os::raw::c_int,
    #[doc = "< Device supports caching locals in L1"]
    pub localL1CacheSupported: ::std::os::raw::c_int,
    #[doc = "< Shared memory available per multiprocessor in bytes"]
    pub sharedMemPerMultiprocessor: usize,
    #[doc = "< 32-bit registers available per multiprocessor"]
    pub regsPerMultiprocessor: ::std::os::raw::c_int,
    #[doc = "< Device supports allocating managed memory on this system"]
    pub managedMemory: ::std::os::raw::c_int,
    #[doc = "< Device is on a multi-GPU board"]
    pub isMultiGpuBoard: ::std::os::raw::c_int,
    #[doc = "< Unique identifier for a group of devices on the same multi-GPU board"]
    pub multiGpuBoardGroupID: ::std::os::raw::c_int,
    #[doc = "< Link between the device and the host supports native atomic operations"]
    pub hostNativeAtomicSupported: ::std::os::raw::c_int,
    #[doc = "< Ratio of single precision performance (in floating-point operations per second) to double precision performance"]
    pub singleToDoublePrecisionPerfRatio: ::std::os::raw::c_int,
    #[doc = "< Device supports coherently accessing pageable memory without calling cudaHostRegister on it"]
    pub pageableMemoryAccess: ::std::os::raw::c_int,
    #[doc = "< Device can coherently access managed memory concurrently with the CPU"]
    pub concurrentManagedAccess: ::std::os::raw::c_int,
    #[doc = "< Device supports Compute Preemption"]
    pub computePreemptionSupported: ::std::os::raw::c_int,
    #[doc = "< Device can access host registered memory at the same virtual address as the CPU"]
    pub canUseHostPointerForRegisteredMem: ::std::os::raw::c_int,
    #[doc = "< Device supports launching cooperative kernels via ::cudaLaunchCooperativeKernel"]
    pub cooperativeLaunch: ::std::os::raw::c_int,
    #[doc = "< Device can participate in cooperative kernels launched via ::cudaLaunchCooperativeKernelMultiDevice"]
    pub cooperativeMultiDeviceLaunch: ::std::os::raw::c_int,
    #[doc = "< Per device maximum shared memory per block usable by special opt in"]
    pub sharedMemPerBlockOptin: usize,
    #[doc = "< Device accesses pageable memory via the host\'s page tables"]
    pub pageableMemoryAccessUsesHostPageTables: ::std::os::raw::c_int,
    #[doc = "< Host can directly access managed memory on the device without migration."]
    pub directManagedMemAccessFromHost: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout_cudaDeviceProp() {
    assert_eq!(
        ::std::mem::size_of::<cudaDeviceProp>(),
        712usize,
        concat!("Size of: ", stringify!(cudaDeviceProp))
    );
    assert_eq!(
        ::std::mem::align_of::<cudaDeviceProp>(),
        8usize,
        concat!("Alignment of ", stringify!(cudaDeviceProp))
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).name as *const _ as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(name)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).uuid as *const _ as usize },
        256usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(uuid)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).luid as *const _ as usize },
        272usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(luid)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).luidDeviceNodeMask as *const _ as usize
        },
        280usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(luidDeviceNodeMask)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).totalGlobalMem as *const _ as usize },
        288usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(totalGlobalMem)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).sharedMemPerBlock as *const _ as usize
        },
        296usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(sharedMemPerBlock)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).regsPerBlock as *const _ as usize },
        304usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(regsPerBlock)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).warpSize as *const _ as usize },
        308usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(warpSize)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).memPitch as *const _ as usize },
        312usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(memPitch)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxThreadsPerBlock as *const _ as usize
        },
        320usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxThreadsPerBlock)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxThreadsDim as *const _ as usize },
        324usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxThreadsDim)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxGridSize as *const _ as usize },
        336usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxGridSize)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).clockRate as *const _ as usize },
        348usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(clockRate)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).totalConstMem as *const _ as usize },
        352usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(totalConstMem)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).major as *const _ as usize },
        360usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(major)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).minor as *const _ as usize },
        364usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(minor)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).textureAlignment as *const _ as usize },
        368usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(textureAlignment)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).texturePitchAlignment as *const _ as usize
        },
        376usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(texturePitchAlignment)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).deviceOverlap as *const _ as usize },
        384usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(deviceOverlap)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).multiProcessorCount as *const _ as usize
        },
        388usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(multiProcessorCount)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).kernelExecTimeoutEnabled as *const _ as usize
        },
        392usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(kernelExecTimeoutEnabled)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).integrated as *const _ as usize },
        396usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(integrated)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).canMapHostMemory as *const _ as usize },
        400usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(canMapHostMemory)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).computeMode as *const _ as usize },
        404usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(computeMode)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture1D as *const _ as usize },
        408usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture1D)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture1DMipmap as *const _ as usize
        },
        412usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture1DMipmap)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture1DLinear as *const _ as usize
        },
        416usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture1DLinear)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture2D as *const _ as usize },
        420usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture2D)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture2DMipmap as *const _ as usize
        },
        428usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture2DMipmap)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture2DLinear as *const _ as usize
        },
        436usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture2DLinear)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture2DGather as *const _ as usize
        },
        448usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture2DGather)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture3D as *const _ as usize },
        456usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture3D)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture3DAlt as *const _ as usize },
        468usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture3DAlt)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTextureCubemap as *const _ as usize
        },
        480usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTextureCubemap)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture1DLayered as *const _ as usize
        },
        484usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture1DLayered)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTexture2DLayered as *const _ as usize
        },
        492usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTexture2DLayered)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxTextureCubemapLayered as *const _ as usize
        },
        504usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxTextureCubemapLayered)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxSurface1D as *const _ as usize },
        512usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxSurface1D)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxSurface2D as *const _ as usize },
        516usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxSurface2D)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).maxSurface3D as *const _ as usize },
        524usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxSurface3D)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxSurface1DLayered as *const _ as usize
        },
        536usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxSurface1DLayered)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxSurface2DLayered as *const _ as usize
        },
        544usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxSurface2DLayered)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxSurfaceCubemap as *const _ as usize
        },
        556usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxSurfaceCubemap)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxSurfaceCubemapLayered as *const _ as usize
        },
        560usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxSurfaceCubemapLayered)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).surfaceAlignment as *const _ as usize },
        568usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(surfaceAlignment)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).concurrentKernels as *const _ as usize
        },
        576usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(concurrentKernels)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).ECCEnabled as *const _ as usize },
        580usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(ECCEnabled)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).pciBusID as *const _ as usize },
        584usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(pciBusID)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).pciDeviceID as *const _ as usize },
        588usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(pciDeviceID)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).pciDomainID as *const _ as usize },
        592usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(pciDomainID)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).tccDriver as *const _ as usize },
        596usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(tccDriver)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).asyncEngineCount as *const _ as usize },
        600usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(asyncEngineCount)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).unifiedAddressing as *const _ as usize
        },
        604usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(unifiedAddressing)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).memoryClockRate as *const _ as usize },
        608usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(memoryClockRate)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).memoryBusWidth as *const _ as usize },
        612usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(memoryBusWidth)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).l2CacheSize as *const _ as usize },
        616usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(l2CacheSize)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).maxThreadsPerMultiProcessor as *const _
                as usize
        },
        620usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(maxThreadsPerMultiProcessor)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).streamPrioritiesSupported as *const _
                as usize
        },
        624usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(streamPrioritiesSupported)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).globalL1CacheSupported as *const _ as usize
        },
        628usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(globalL1CacheSupported)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).localL1CacheSupported as *const _ as usize
        },
        632usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(localL1CacheSupported)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).sharedMemPerMultiprocessor as *const _
                as usize
        },
        640usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(sharedMemPerMultiprocessor)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).regsPerMultiprocessor as *const _ as usize
        },
        648usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(regsPerMultiprocessor)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).managedMemory as *const _ as usize },
        652usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(managedMemory)
        )
    );
    assert_eq!(
        unsafe { &(*(::std::ptr::null::<cudaDeviceProp>())).isMultiGpuBoard as *const _ as usize },
        656usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(isMultiGpuBoard)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).multiGpuBoardGroupID as *const _ as usize
        },
        660usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(multiGpuBoardGroupID)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).hostNativeAtomicSupported as *const _
                as usize
        },
        664usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(hostNativeAtomicSupported)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).singleToDoublePrecisionPerfRatio as *const _
                as usize
        },
        668usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(singleToDoublePrecisionPerfRatio)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).pageableMemoryAccess as *const _ as usize
        },
        672usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(pageableMemoryAccess)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).concurrentManagedAccess as *const _ as usize
        },
        676usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(concurrentManagedAccess)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).computePreemptionSupported as *const _
                as usize
        },
        680usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(computePreemptionSupported)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).canUseHostPointerForRegisteredMem as *const _
                as usize
        },
        684usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(canUseHostPointerForRegisteredMem)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).cooperativeLaunch as *const _ as usize
        },
        688usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(cooperativeLaunch)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).cooperativeMultiDeviceLaunch as *const _
                as usize
        },
        692usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(cooperativeMultiDeviceLaunch)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).sharedMemPerBlockOptin as *const _ as usize
        },
        696usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(sharedMemPerBlockOptin)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).pageableMemoryAccessUsesHostPageTables
                as *const _ as usize
        },
        704usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(pageableMemoryAccessUsesHostPageTables)
        )
    );
    assert_eq!(
        unsafe {
            &(*(::std::ptr::null::<cudaDeviceProp>())).directManagedMemAccessFromHost as *const _
                as usize
        },
        708usize,
        concat!(
            "Offset of field: ",
            stringify!(cudaDeviceProp),
            "::",
            stringify!(directManagedMemAccessFromHost)
        )
    );
}
#[doc = " CUDA Error types"]
pub use self::cudaError as cudaError_t;
#[doc = " CUDA stream"]
pub type cudaStream_t = *mut CUstream_st;
#[doc = " CUDA event types"]
pub type cudaEvent_t = *mut CUevent_st;
#[doc = " CUDA graphics resource types"]
pub type cudaGraphicsResource_t = *mut cudaGraphicsResource;
