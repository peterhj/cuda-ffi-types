/* automatically generated by rust-bindgen */

# [ doc = " The API call returned with no errors. In the case of query calls, this" ] # [ doc = " can also mean that the operation being queried is complete (see" ] # [ doc = " ::cudaEventQuery() and ::cudaStreamQuery())." ] pub const cudaError_cudaSuccess : cudaError = 0 ; # [ doc = " The device function being invoked (usually via ::cudaLaunchKernel()) was not" ] # [ doc = " previously configured via the ::cudaConfigureCall() function." ] pub const cudaError_cudaErrorMissingConfiguration : cudaError = 1 ; # [ doc = " The API call failed because it was unable to allocate enough memory to" ] # [ doc = " perform the requested operation." ] pub const cudaError_cudaErrorMemoryAllocation : cudaError = 2 ; # [ doc = " The API call failed because the CUDA driver and runtime could not be" ] # [ doc = " initialized." ] pub const cudaError_cudaErrorInitializationError : cudaError = 3 ; # [ doc = " An exception occurred on the device while executing a kernel. Common" ] # [ doc = " causes include dereferencing an invalid device pointer and accessing" ] # [ doc = " out of bounds shared memory. The device cannot be used until" ] # [ doc = " ::cudaThreadExit() is called. All existing device memory allocations" ] # [ doc = " are invalid and must be reconstructed if the program is to continue" ] # [ doc = " using CUDA." ] pub const cudaError_cudaErrorLaunchFailure : cudaError = 4 ; # [ doc = " This indicated that a previous kernel launch failed. This was previously" ] # [ doc = " used for device emulation of kernel launches." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was" ] # [ doc = " removed with the CUDA 3.1 release." ] pub const cudaError_cudaErrorPriorLaunchFailure : cudaError = 5 ; # [ doc = " This indicates that the device kernel took too long to execute. This can" ] # [ doc = " only occur if timeouts are enabled - see the device property" ] # [ doc = " \\ref ::cudaDeviceProp::kernelExecTimeoutEnabled \"kernelExecTimeoutEnabled\"" ] # [ doc = " for more information." ] # [ doc = " This leaves the process in an inconsistent state and any further CUDA work" ] # [ doc = " will return the same error. To continue using CUDA, the process must be terminated" ] # [ doc = " and relaunched." ] pub const cudaError_cudaErrorLaunchTimeout : cudaError = 6 ; # [ doc = " This indicates that a launch did not occur because it did not have" ] # [ doc = " appropriate resources. Although this error is similar to" ] # [ doc = " ::cudaErrorInvalidConfiguration, this error usually indicates that the" ] # [ doc = " user has attempted to pass too many arguments to the device kernel, or the" ] # [ doc = " kernel launch specifies too many threads for the kernel\'s register count." ] pub const cudaError_cudaErrorLaunchOutOfResources : cudaError = 7 ; # [ doc = " The requested device function does not exist or is not compiled for the" ] # [ doc = " proper device architecture." ] pub const cudaError_cudaErrorInvalidDeviceFunction : cudaError = 8 ; # [ doc = " This indicates that a kernel launch is requesting resources that can" ] # [ doc = " never be satisfied by the current device. Requesting more shared memory" ] # [ doc = " per block than the device supports will trigger this error, as will" ] # [ doc = " requesting too many threads or blocks. See ::cudaDeviceProp for more" ] # [ doc = " device limitations." ] pub const cudaError_cudaErrorInvalidConfiguration : cudaError = 9 ; # [ doc = " This indicates that the device ordinal supplied by the user does not" ] # [ doc = " correspond to a valid CUDA device." ] pub const cudaError_cudaErrorInvalidDevice : cudaError = 10 ; # [ doc = " This indicates that one or more of the parameters passed to the API call" ] # [ doc = " is not within an acceptable range of values." ] pub const cudaError_cudaErrorInvalidValue : cudaError = 11 ; # [ doc = " This indicates that one or more of the pitch-related parameters passed" ] # [ doc = " to the API call is not within the acceptable range for pitch." ] pub const cudaError_cudaErrorInvalidPitchValue : cudaError = 12 ; # [ doc = " This indicates that the symbol name/identifier passed to the API call" ] # [ doc = " is not a valid name or identifier." ] pub const cudaError_cudaErrorInvalidSymbol : cudaError = 13 ; # [ doc = " This indicates that the buffer object could not be mapped." ] pub const cudaError_cudaErrorMapBufferObjectFailed : cudaError = 14 ; # [ doc = " This indicates that the buffer object could not be unmapped." ] pub const cudaError_cudaErrorUnmapBufferObjectFailed : cudaError = 15 ; # [ doc = " This indicates that at least one host pointer passed to the API call is" ] # [ doc = " not a valid host pointer." ] pub const cudaError_cudaErrorInvalidHostPointer : cudaError = 16 ; # [ doc = " This indicates that at least one device pointer passed to the API call is" ] # [ doc = " not a valid device pointer." ] pub const cudaError_cudaErrorInvalidDevicePointer : cudaError = 17 ; # [ doc = " This indicates that the texture passed to the API call is not a valid" ] # [ doc = " texture." ] pub const cudaError_cudaErrorInvalidTexture : cudaError = 18 ; # [ doc = " This indicates that the texture binding is not valid. This occurs if you" ] # [ doc = " call ::cudaGetTextureAlignmentOffset() with an unbound texture." ] pub const cudaError_cudaErrorInvalidTextureBinding : cudaError = 19 ; # [ doc = " This indicates that the channel descriptor passed to the API call is not" ] # [ doc = " valid. This occurs if the format is not one of the formats specified by" ] # [ doc = " ::cudaChannelFormatKind, or if one of the dimensions is invalid." ] pub const cudaError_cudaErrorInvalidChannelDescriptor : cudaError = 20 ; # [ doc = " This indicates that the direction of the memcpy passed to the API call is" ] # [ doc = " not one of the types specified by ::cudaMemcpyKind." ] pub const cudaError_cudaErrorInvalidMemcpyDirection : cudaError = 21 ; # [ doc = " This indicated that the user has taken the address of a constant variable," ] # [ doc = " which was forbidden up until the CUDA 3.1 release." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 3.1. Variables in constant" ] # [ doc = " memory may now have their address taken by the runtime via" ] # [ doc = " ::cudaGetSymbolAddress()." ] pub const cudaError_cudaErrorAddressOfConstant : cudaError = 22 ; # [ doc = " This indicated that a texture fetch was not able to be performed." ] # [ doc = " This was previously used for device emulation of texture operations." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was" ] # [ doc = " removed with the CUDA 3.1 release." ] pub const cudaError_cudaErrorTextureFetchFailed : cudaError = 23 ; # [ doc = " This indicated that a texture was not bound for access." ] # [ doc = " This was previously used for device emulation of texture operations." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was" ] # [ doc = " removed with the CUDA 3.1 release." ] pub const cudaError_cudaErrorTextureNotBound : cudaError = 24 ; # [ doc = " This indicated that a synchronization operation had failed." ] # [ doc = " This was previously used for some device emulation functions." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was" ] # [ doc = " removed with the CUDA 3.1 release." ] pub const cudaError_cudaErrorSynchronizationError : cudaError = 25 ; # [ doc = " This indicates that a non-float texture was being accessed with linear" ] # [ doc = " filtering. This is not supported by CUDA." ] pub const cudaError_cudaErrorInvalidFilterSetting : cudaError = 26 ; # [ doc = " This indicates that an attempt was made to read a non-float texture as a" ] # [ doc = " normalized float. This is not supported by CUDA." ] pub const cudaError_cudaErrorInvalidNormSetting : cudaError = 27 ; # [ doc = " Mixing of device and device emulation code was not allowed." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was" ] # [ doc = " removed with the CUDA 3.1 release." ] pub const cudaError_cudaErrorMixedDeviceExecution : cudaError = 28 ; # [ doc = " This indicates that a CUDA Runtime API call cannot be executed because" ] # [ doc = " it is being called during process shut down, at a point in time after" ] # [ doc = " CUDA driver has been unloaded." ] pub const cudaError_cudaErrorCudartUnloading : cudaError = 29 ; # [ doc = " This indicates that an unknown internal error has occurred." ] pub const cudaError_cudaErrorUnknown : cudaError = 30 ; # [ doc = " This indicates that the API call is not yet implemented. Production" ] # [ doc = " releases of CUDA will never return this error." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 4.1." ] pub const cudaError_cudaErrorNotYetImplemented : cudaError = 31 ; # [ doc = " This indicated that an emulated device pointer exceeded the 32-bit address" ] # [ doc = " range." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 3.1. Device emulation mode was" ] # [ doc = " removed with the CUDA 3.1 release." ] pub const cudaError_cudaErrorMemoryValueTooLarge : cudaError = 32 ; # [ doc = " This indicates that a resource handle passed to the API call was not" ] # [ doc = " valid. Resource handles are opaque types like ::cudaStream_t and" ] # [ doc = " ::cudaEvent_t." ] pub const cudaError_cudaErrorInvalidResourceHandle : cudaError = 33 ; # [ doc = " This indicates that asynchronous operations issued previously have not" ] # [ doc = " completed yet. This result is not actually an error, but must be indicated" ] # [ doc = " differently than ::cudaSuccess (which indicates completion). Calls that" ] # [ doc = " may return this value include ::cudaEventQuery() and ::cudaStreamQuery()." ] pub const cudaError_cudaErrorNotReady : cudaError = 34 ; # [ doc = " This indicates that the installed NVIDIA CUDA driver is older than the" ] # [ doc = " CUDA runtime library. This is not a supported configuration. Users should" ] # [ doc = " install an updated NVIDIA display driver to allow the application to run." ] pub const cudaError_cudaErrorInsufficientDriver : cudaError = 35 ; # [ doc = " This indicates that the user has called ::cudaSetValidDevices()," ] # [ doc = " ::cudaSetDeviceFlags(), ::cudaD3D9SetDirect3DDevice()," ] # [ doc = " ::cudaD3D10SetDirect3DDevice, ::cudaD3D11SetDirect3DDevice(), or" ] # [ doc = " ::cudaVDPAUSetVDPAUDevice() after initializing the CUDA runtime by" ] # [ doc = " calling non-device management operations (allocating memory and" ] # [ doc = " launching kernels are examples of non-device management operations)." ] # [ doc = " This error can also be returned if using runtime/driver" ] # [ doc = " interoperability and there is an existing ::CUcontext active on the" ] # [ doc = " host thread." ] pub const cudaError_cudaErrorSetOnActiveProcess : cudaError = 36 ; # [ doc = " This indicates that the surface passed to the API call is not a valid" ] # [ doc = " surface." ] pub const cudaError_cudaErrorInvalidSurface : cudaError = 37 ; # [ doc = " This indicates that no CUDA-capable devices were detected by the installed" ] # [ doc = " CUDA driver." ] pub const cudaError_cudaErrorNoDevice : cudaError = 38 ; # [ doc = " This indicates that an uncorrectable ECC error was detected during" ] # [ doc = " execution." ] pub const cudaError_cudaErrorECCUncorrectable : cudaError = 39 ; # [ doc = " This indicates that a link to a shared object failed to resolve." ] pub const cudaError_cudaErrorSharedObjectSymbolNotFound : cudaError = 40 ; # [ doc = " This indicates that initialization of a shared object failed." ] pub const cudaError_cudaErrorSharedObjectInitFailed : cudaError = 41 ; # [ doc = " This indicates that the ::cudaLimit passed to the API call is not" ] # [ doc = " supported by the active device." ] pub const cudaError_cudaErrorUnsupportedLimit : cudaError = 42 ; # [ doc = " This indicates that multiple global or constant variables (across separate" ] # [ doc = " CUDA source files in the application) share the same string name." ] pub const cudaError_cudaErrorDuplicateVariableName : cudaError = 43 ; # [ doc = " This indicates that multiple textures (across separate CUDA source" ] # [ doc = " files in the application) share the same string name." ] pub const cudaError_cudaErrorDuplicateTextureName : cudaError = 44 ; # [ doc = " This indicates that multiple surfaces (across separate CUDA source" ] # [ doc = " files in the application) share the same string name." ] pub const cudaError_cudaErrorDuplicateSurfaceName : cudaError = 45 ; # [ doc = " This indicates that all CUDA devices are busy or unavailable at the current" ] # [ doc = " time. Devices are often busy/unavailable due to use of" ] # [ doc = " ::cudaComputeModeExclusive, ::cudaComputeModeProhibited or when long" ] # [ doc = " running CUDA kernels have filled up the GPU and are blocking new work" ] # [ doc = " from starting. They can also be unavailable due to memory constraints" ] # [ doc = " on a device that already has active CUDA work being performed." ] pub const cudaError_cudaErrorDevicesUnavailable : cudaError = 46 ; # [ doc = " This indicates that the device kernel image is invalid." ] pub const cudaError_cudaErrorInvalidKernelImage : cudaError = 47 ; # [ doc = " This indicates that there is no kernel image available that is suitable" ] # [ doc = " for the device. This can occur when a user specifies code generation" ] # [ doc = " options for a particular CUDA source file that do not include the" ] # [ doc = " corresponding device configuration." ] pub const cudaError_cudaErrorNoKernelImageForDevice : cudaError = 48 ; # [ doc = " This indicates that the current context is not compatible with this" ] # [ doc = " the CUDA Runtime. This can only occur if you are using CUDA" ] # [ doc = " Runtime/Driver interoperability and have created an existing Driver" ] # [ doc = " context using the driver API. The Driver context may be incompatible" ] # [ doc = " either because the Driver context was created using an older version" ] # [ doc = " of the API, because the Runtime API call expects a primary driver" ] # [ doc = " context and the Driver context is not primary, or because the Driver" ] # [ doc = " context has been destroyed. Please see \\ref CUDART_DRIVER \"Interactions" ] # [ doc = " with the CUDA Driver API\" for more information." ] pub const cudaError_cudaErrorIncompatibleDriverContext : cudaError = 49 ; # [ doc = " This error indicates that a call to ::cudaDeviceEnablePeerAccess() is" ] # [ doc = " trying to re-enable peer addressing on from a context which has already" ] # [ doc = " had peer addressing enabled." ] pub const cudaError_cudaErrorPeerAccessAlreadyEnabled : cudaError = 50 ; # [ doc = " This error indicates that ::cudaDeviceDisablePeerAccess() is trying to" ] # [ doc = " disable peer addressing which has not been enabled yet via" ] # [ doc = " ::cudaDeviceEnablePeerAccess()." ] pub const cudaError_cudaErrorPeerAccessNotEnabled : cudaError = 51 ; # [ doc = " This indicates that a call tried to access an exclusive-thread device that" ] # [ doc = " is already in use by a different thread." ] pub const cudaError_cudaErrorDeviceAlreadyInUse : cudaError = 54 ; # [ doc = " This indicates profiler is not initialized for this run. This can" ] # [ doc = " happen when the application is running with external profiling tools" ] # [ doc = " like visual profiler." ] pub const cudaError_cudaErrorProfilerDisabled : cudaError = 55 ; # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 5.0. It is no longer an error" ] # [ doc = " to attempt to enable/disable the profiling via ::cudaProfilerStart or" ] # [ doc = " ::cudaProfilerStop without initialization." ] pub const cudaError_cudaErrorProfilerNotInitialized : cudaError = 56 ; # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 5.0. It is no longer an error" ] # [ doc = " to call cudaProfilerStart() when profiling is already enabled." ] pub const cudaError_cudaErrorProfilerAlreadyStarted : cudaError = 57 ; # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 5.0. It is no longer an error" ] # [ doc = " to call cudaProfilerStop() when profiling is already disabled." ] pub const cudaError_cudaErrorProfilerAlreadyStopped : cudaError = 58 ; # [ doc = " An assert triggered in device code during kernel execution. The device" ] # [ doc = " cannot be used again until ::cudaThreadExit() is called. All existing" ] # [ doc = " allocations are invalid and must be reconstructed if the program is to" ] # [ doc = " continue using CUDA." ] pub const cudaError_cudaErrorAssert : cudaError = 59 ; # [ doc = " This error indicates that the hardware resources required to enable" ] # [ doc = " peer access have been exhausted for one or more of the devices" ] # [ doc = " passed to ::cudaEnablePeerAccess()." ] pub const cudaError_cudaErrorTooManyPeers : cudaError = 60 ; # [ doc = " This error indicates that the memory range passed to ::cudaHostRegister()" ] # [ doc = " has already been registered." ] pub const cudaError_cudaErrorHostMemoryAlreadyRegistered : cudaError = 61 ; # [ doc = " This error indicates that the pointer passed to ::cudaHostUnregister()" ] # [ doc = " does not correspond to any currently registered memory region." ] pub const cudaError_cudaErrorHostMemoryNotRegistered : cudaError = 62 ; # [ doc = " This error indicates that an OS call failed." ] pub const cudaError_cudaErrorOperatingSystem : cudaError = 63 ; # [ doc = " This error indicates that P2P access is not supported across the given" ] # [ doc = " devices." ] pub const cudaError_cudaErrorPeerAccessUnsupported : cudaError = 64 ; # [ doc = " This error indicates that a device runtime grid launch did not occur" ] # [ doc = " because the depth of the child grid would exceed the maximum supported" ] # [ doc = " number of nested grid launches." ] pub const cudaError_cudaErrorLaunchMaxDepthExceeded : cudaError = 65 ; # [ doc = " This error indicates that a grid launch did not occur because the kernel" ] # [ doc = " uses file-scoped textures which are unsupported by the device runtime." ] # [ doc = " Kernels launched via the device runtime only support textures created with" ] # [ doc = " the Texture Object API\'s." ] pub const cudaError_cudaErrorLaunchFileScopedTex : cudaError = 66 ; # [ doc = " This error indicates that a grid launch did not occur because the kernel" ] # [ doc = " uses file-scoped surfaces which are unsupported by the device runtime." ] # [ doc = " Kernels launched via the device runtime only support surfaces created with" ] # [ doc = " the Surface Object API\'s." ] pub const cudaError_cudaErrorLaunchFileScopedSurf : cudaError = 67 ; # [ doc = " This error indicates that a call to ::cudaDeviceSynchronize made from" ] # [ doc = " the device runtime failed because the call was made at grid depth greater" ] # [ doc = " than than either the default (2 levels of grids) or user specified device" ] # [ doc = " limit ::cudaLimitDevRuntimeSyncDepth. To be able to synchronize on" ] # [ doc = " launched grids at a greater depth successfully, the maximum nested" ] # [ doc = " depth at which ::cudaDeviceSynchronize will be called must be specified" ] # [ doc = " with the ::cudaLimitDevRuntimeSyncDepth limit to the ::cudaDeviceSetLimit" ] # [ doc = " api before the host-side launch of a kernel using the device runtime." ] # [ doc = " Keep in mind that additional levels of sync depth require the runtime" ] # [ doc = " to reserve large amounts of device memory that cannot be used for" ] # [ doc = " user allocations." ] pub const cudaError_cudaErrorSyncDepthExceeded : cudaError = 68 ; # [ doc = " This error indicates that a device runtime grid launch failed because" ] # [ doc = " the launch would exceed the limit ::cudaLimitDevRuntimePendingLaunchCount." ] # [ doc = " For this launch to proceed successfully, ::cudaDeviceSetLimit must be" ] # [ doc = " called to set the ::cudaLimitDevRuntimePendingLaunchCount to be higher" ] # [ doc = " than the upper bound of outstanding launches that can be issued to the" ] # [ doc = " device runtime. Keep in mind that raising the limit of pending device" ] # [ doc = " runtime launches will require the runtime to reserve device memory that" ] # [ doc = " cannot be used for user allocations." ] pub const cudaError_cudaErrorLaunchPendingCountExceeded : cudaError = 69 ; # [ doc = " This error indicates the attempted operation is not permitted." ] pub const cudaError_cudaErrorNotPermitted : cudaError = 70 ; # [ doc = " This error indicates the attempted operation is not supported" ] # [ doc = " on the current system or device." ] pub const cudaError_cudaErrorNotSupported : cudaError = 71 ; # [ doc = " Device encountered an error in the call stack during kernel execution," ] # [ doc = " possibly due to stack corruption or exceeding the stack size limit." ] # [ doc = " This leaves the process in an inconsistent state and any further CUDA work" ] # [ doc = " will return the same error. To continue using CUDA, the process must be terminated" ] # [ doc = " and relaunched." ] pub const cudaError_cudaErrorHardwareStackError : cudaError = 72 ; # [ doc = " The device encountered an illegal instruction during kernel execution" ] # [ doc = " This leaves the process in an inconsistent state and any further CUDA work" ] # [ doc = " will return the same error. To continue using CUDA, the process must be terminated" ] # [ doc = " and relaunched." ] pub const cudaError_cudaErrorIllegalInstruction : cudaError = 73 ; # [ doc = " The device encountered a load or store instruction" ] # [ doc = " on a memory address which is not aligned." ] # [ doc = " This leaves the process in an inconsistent state and any further CUDA work" ] # [ doc = " will return the same error. To continue using CUDA, the process must be terminated" ] # [ doc = " and relaunched." ] pub const cudaError_cudaErrorMisalignedAddress : cudaError = 74 ; # [ doc = " While executing a kernel, the device encountered an instruction" ] # [ doc = " which can only operate on memory locations in certain address spaces" ] # [ doc = " (global, shared, or local), but was supplied a memory address not" ] # [ doc = " belonging to an allowed address space." ] # [ doc = " This leaves the process in an inconsistent state and any further CUDA work" ] # [ doc = " will return the same error. To continue using CUDA, the process must be terminated" ] # [ doc = " and relaunched." ] pub const cudaError_cudaErrorInvalidAddressSpace : cudaError = 75 ; # [ doc = " The device encountered an invalid program counter." ] # [ doc = " This leaves the process in an inconsistent state and any further CUDA work" ] # [ doc = " will return the same error. To continue using CUDA, the process must be terminated" ] # [ doc = " and relaunched." ] pub const cudaError_cudaErrorInvalidPc : cudaError = 76 ; # [ doc = " The device encountered a load or store instruction on an invalid memory address." ] # [ doc = " This leaves the process in an inconsistent state and any further CUDA work" ] # [ doc = " will return the same error. To continue using CUDA, the process must be terminated" ] # [ doc = " and relaunched." ] pub const cudaError_cudaErrorIllegalAddress : cudaError = 77 ; # [ doc = " A PTX compilation failed. The runtime may fall back to compiling PTX if" ] # [ doc = " an application does not contain a suitable binary for the current device." ] pub const cudaError_cudaErrorInvalidPtx : cudaError = 78 ; # [ doc = " This indicates an error with the OpenGL or DirectX context." ] pub const cudaError_cudaErrorInvalidGraphicsContext : cudaError = 79 ; # [ doc = " This indicates that an uncorrectable NVLink error was detected during the" ] # [ doc = " execution." ] pub const cudaError_cudaErrorNvlinkUncorrectable : cudaError = 80 ; # [ doc = " This indicates that the PTX JIT compiler library was not found. The JIT Compiler" ] # [ doc = " library is used for PTX compilation. The runtime may fall back to compiling PTX" ] # [ doc = " if an application does not contain a suitable binary for the current device." ] pub const cudaError_cudaErrorJitCompilerNotFound : cudaError = 81 ; # [ doc = " This error indicates that the number of blocks launched per grid for a kernel that was" ] # [ doc = " launched via either ::cudaLaunchCooperativeKernel or ::cudaLaunchCooperativeKernelMultiDevice" ] # [ doc = " exceeds the maximum number of blocks as allowed by ::cudaOccupancyMaxActiveBlocksPerMultiprocessor" ] # [ doc = " or ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags times the number of multiprocessors" ] # [ doc = " as specified by the device attribute ::cudaDevAttrMultiProcessorCount." ] pub const cudaError_cudaErrorCooperativeLaunchTooLarge : cudaError = 82 ; # [ doc = " This indicates an internal startup failure in the CUDA runtime." ] pub const cudaError_cudaErrorStartupFailure : cudaError = 127 ; # [ doc = " Any unhandled CUDA driver error is added to this value and returned via" ] # [ doc = " the runtime. Production releases of CUDA should not return such errors." ] # [ doc = " \\deprecated" ] # [ doc = " This error return is deprecated as of CUDA 4.1." ] pub const cudaError_cudaErrorApiFailureBase : cudaError = 10000 ; # [ doc = " CUDA error types" ] pub type cudaError = u32 ; # [ doc = "< Host   -> Host" ] pub const cudaMemcpyKind_cudaMemcpyHostToHost : cudaMemcpyKind = 0 ; # [ doc = "< Host   -> Device" ] pub const cudaMemcpyKind_cudaMemcpyHostToDevice : cudaMemcpyKind = 1 ; # [ doc = "< Device -> Host" ] pub const cudaMemcpyKind_cudaMemcpyDeviceToHost : cudaMemcpyKind = 2 ; # [ doc = "< Device -> Device" ] pub const cudaMemcpyKind_cudaMemcpyDeviceToDevice : cudaMemcpyKind = 3 ; # [ doc = "< Direction of the transfer is inferred from the pointer values. Requires unified virtual addressing" ] pub const cudaMemcpyKind_cudaMemcpyDefault : cudaMemcpyKind = 4 ; # [ doc = " CUDA memory copy types" ] pub type cudaMemcpyKind = u32 ; # [ doc = " CUDA graphics interop resource" ] # [ repr ( C ) ] # [ derive ( Debug , Copy , Clone ) ] pub struct cudaGraphicsResource { _unused : [ u8 ; 0 ] , } # [ doc = "< Data will mostly be read and only occassionally be written to" ] pub const cudaMemoryAdvise_cudaMemAdviseSetReadMostly : cudaMemoryAdvise = 1 ; # [ doc = "< Undo the effect of ::cudaMemAdviseSetReadMostly" ] pub const cudaMemoryAdvise_cudaMemAdviseUnsetReadMostly : cudaMemoryAdvise = 2 ; # [ doc = "< Set the preferred location for the data as the specified device" ] pub const cudaMemoryAdvise_cudaMemAdviseSetPreferredLocation : cudaMemoryAdvise = 3 ; # [ doc = "< Clear the preferred location for the data" ] pub const cudaMemoryAdvise_cudaMemAdviseUnsetPreferredLocation : cudaMemoryAdvise = 4 ; # [ doc = "< Data will be accessed by the specified device, so prevent page faults as much as possible" ] pub const cudaMemoryAdvise_cudaMemAdviseSetAccessedBy : cudaMemoryAdvise = 5 ; # [ doc = "< Let the Unified Memory subsystem decide on the page faulting policy for the specified device" ] pub const cudaMemoryAdvise_cudaMemAdviseUnsetAccessedBy : cudaMemoryAdvise = 6 ; # [ doc = " CUDA Memory Advise values" ] pub type cudaMemoryAdvise = u32 ; # [ doc = "< Whether the range will mostly be read and only occassionally be written to" ] pub const cudaMemRangeAttribute_cudaMemRangeAttributeReadMostly : cudaMemRangeAttribute = 1 ; # [ doc = "< The preferred location of the range" ] pub const cudaMemRangeAttribute_cudaMemRangeAttributePreferredLocation : cudaMemRangeAttribute = 2 ; # [ doc = "< Memory range has ::cudaMemAdviseSetAccessedBy set for specified device" ] pub const cudaMemRangeAttribute_cudaMemRangeAttributeAccessedBy : cudaMemRangeAttribute = 3 ; # [ doc = "< The last location to which the range was prefetched" ] pub const cudaMemRangeAttribute_cudaMemRangeAttributeLastPrefetchLocation : cudaMemRangeAttribute = 4 ; # [ doc = " CUDA range attributes" ] pub type cudaMemRangeAttribute = u32 ; # [ doc = "< Maximum number of threads per block" ] pub const cudaDeviceAttr_cudaDevAttrMaxThreadsPerBlock : cudaDeviceAttr = 1 ; # [ doc = "< Maximum block dimension X" ] pub const cudaDeviceAttr_cudaDevAttrMaxBlockDimX : cudaDeviceAttr = 2 ; # [ doc = "< Maximum block dimension Y" ] pub const cudaDeviceAttr_cudaDevAttrMaxBlockDimY : cudaDeviceAttr = 3 ; # [ doc = "< Maximum block dimension Z" ] pub const cudaDeviceAttr_cudaDevAttrMaxBlockDimZ : cudaDeviceAttr = 4 ; # [ doc = "< Maximum grid dimension X" ] pub const cudaDeviceAttr_cudaDevAttrMaxGridDimX : cudaDeviceAttr = 5 ; # [ doc = "< Maximum grid dimension Y" ] pub const cudaDeviceAttr_cudaDevAttrMaxGridDimY : cudaDeviceAttr = 6 ; # [ doc = "< Maximum grid dimension Z" ] pub const cudaDeviceAttr_cudaDevAttrMaxGridDimZ : cudaDeviceAttr = 7 ; # [ doc = "< Maximum shared memory available per block in bytes" ] pub const cudaDeviceAttr_cudaDevAttrMaxSharedMemoryPerBlock : cudaDeviceAttr = 8 ; # [ doc = "< Memory available on device for __constant__ variables in a CUDA C kernel in bytes" ] pub const cudaDeviceAttr_cudaDevAttrTotalConstantMemory : cudaDeviceAttr = 9 ; # [ doc = "< Warp size in threads" ] pub const cudaDeviceAttr_cudaDevAttrWarpSize : cudaDeviceAttr = 10 ; # [ doc = "< Maximum pitch in bytes allowed by memory copies" ] pub const cudaDeviceAttr_cudaDevAttrMaxPitch : cudaDeviceAttr = 11 ; # [ doc = "< Maximum number of 32-bit registers available per block" ] pub const cudaDeviceAttr_cudaDevAttrMaxRegistersPerBlock : cudaDeviceAttr = 12 ; # [ doc = "< Peak clock frequency in kilohertz" ] pub const cudaDeviceAttr_cudaDevAttrClockRate : cudaDeviceAttr = 13 ; # [ doc = "< Alignment requirement for textures" ] pub const cudaDeviceAttr_cudaDevAttrTextureAlignment : cudaDeviceAttr = 14 ; # [ doc = "< Device can possibly copy memory and execute a kernel concurrently" ] pub const cudaDeviceAttr_cudaDevAttrGpuOverlap : cudaDeviceAttr = 15 ; # [ doc = "< Number of multiprocessors on device" ] pub const cudaDeviceAttr_cudaDevAttrMultiProcessorCount : cudaDeviceAttr = 16 ; # [ doc = "< Specifies whether there is a run time limit on kernels" ] pub const cudaDeviceAttr_cudaDevAttrKernelExecTimeout : cudaDeviceAttr = 17 ; # [ doc = "< Device is integrated with host memory" ] pub const cudaDeviceAttr_cudaDevAttrIntegrated : cudaDeviceAttr = 18 ; # [ doc = "< Device can map host memory into CUDA address space" ] pub const cudaDeviceAttr_cudaDevAttrCanMapHostMemory : cudaDeviceAttr = 19 ; # [ doc = "< Compute mode (See ::cudaComputeMode for details)" ] pub const cudaDeviceAttr_cudaDevAttrComputeMode : cudaDeviceAttr = 20 ; # [ doc = "< Maximum 1D texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DWidth : cudaDeviceAttr = 21 ; # [ doc = "< Maximum 2D texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DWidth : cudaDeviceAttr = 22 ; # [ doc = "< Maximum 2D texture height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DHeight : cudaDeviceAttr = 23 ; # [ doc = "< Maximum 3D texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DWidth : cudaDeviceAttr = 24 ; # [ doc = "< Maximum 3D texture height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DHeight : cudaDeviceAttr = 25 ; # [ doc = "< Maximum 3D texture depth" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DDepth : cudaDeviceAttr = 26 ; # [ doc = "< Maximum 2D layered texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLayeredWidth : cudaDeviceAttr = 27 ; # [ doc = "< Maximum 2D layered texture height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLayeredHeight : cudaDeviceAttr = 28 ; # [ doc = "< Maximum layers in a 2D layered texture" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLayeredLayers : cudaDeviceAttr = 29 ; # [ doc = "< Alignment requirement for surfaces" ] pub const cudaDeviceAttr_cudaDevAttrSurfaceAlignment : cudaDeviceAttr = 30 ; # [ doc = "< Device can possibly execute multiple kernels concurrently" ] pub const cudaDeviceAttr_cudaDevAttrConcurrentKernels : cudaDeviceAttr = 31 ; # [ doc = "< Device has ECC support enabled" ] pub const cudaDeviceAttr_cudaDevAttrEccEnabled : cudaDeviceAttr = 32 ; # [ doc = "< PCI bus ID of the device" ] pub const cudaDeviceAttr_cudaDevAttrPciBusId : cudaDeviceAttr = 33 ; # [ doc = "< PCI device ID of the device" ] pub const cudaDeviceAttr_cudaDevAttrPciDeviceId : cudaDeviceAttr = 34 ; # [ doc = "< Device is using TCC driver model" ] pub const cudaDeviceAttr_cudaDevAttrTccDriver : cudaDeviceAttr = 35 ; # [ doc = "< Peak memory clock frequency in kilohertz" ] pub const cudaDeviceAttr_cudaDevAttrMemoryClockRate : cudaDeviceAttr = 36 ; # [ doc = "< Global memory bus width in bits" ] pub const cudaDeviceAttr_cudaDevAttrGlobalMemoryBusWidth : cudaDeviceAttr = 37 ; # [ doc = "< Size of L2 cache in bytes" ] pub const cudaDeviceAttr_cudaDevAttrL2CacheSize : cudaDeviceAttr = 38 ; # [ doc = "< Maximum resident threads per multiprocessor" ] pub const cudaDeviceAttr_cudaDevAttrMaxThreadsPerMultiProcessor : cudaDeviceAttr = 39 ; # [ doc = "< Number of asynchronous engines" ] pub const cudaDeviceAttr_cudaDevAttrAsyncEngineCount : cudaDeviceAttr = 40 ; # [ doc = "< Device shares a unified address space with the host" ] pub const cudaDeviceAttr_cudaDevAttrUnifiedAddressing : cudaDeviceAttr = 41 ; # [ doc = "< Maximum 1D layered texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DLayeredWidth : cudaDeviceAttr = 42 ; # [ doc = "< Maximum layers in a 1D layered texture" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DLayeredLayers : cudaDeviceAttr = 43 ; # [ doc = "< Maximum 2D texture width if cudaArrayTextureGather is set" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DGatherWidth : cudaDeviceAttr = 45 ; # [ doc = "< Maximum 2D texture height if cudaArrayTextureGather is set" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DGatherHeight : cudaDeviceAttr = 46 ; # [ doc = "< Alternate maximum 3D texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DWidthAlt : cudaDeviceAttr = 47 ; # [ doc = "< Alternate maximum 3D texture height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DHeightAlt : cudaDeviceAttr = 48 ; # [ doc = "< Alternate maximum 3D texture depth" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture3DDepthAlt : cudaDeviceAttr = 49 ; # [ doc = "< PCI domain ID of the device" ] pub const cudaDeviceAttr_cudaDevAttrPciDomainId : cudaDeviceAttr = 50 ; # [ doc = "< Pitch alignment requirement for textures" ] pub const cudaDeviceAttr_cudaDevAttrTexturePitchAlignment : cudaDeviceAttr = 51 ; # [ doc = "< Maximum cubemap texture width/height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTextureCubemapWidth : cudaDeviceAttr = 52 ; # [ doc = "< Maximum cubemap layered texture width/height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTextureCubemapLayeredWidth : cudaDeviceAttr = 53 ; # [ doc = "< Maximum layers in a cubemap layered texture" ] pub const cudaDeviceAttr_cudaDevAttrMaxTextureCubemapLayeredLayers : cudaDeviceAttr = 54 ; # [ doc = "< Maximum 1D surface width" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface1DWidth : cudaDeviceAttr = 55 ; # [ doc = "< Maximum 2D surface width" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DWidth : cudaDeviceAttr = 56 ; # [ doc = "< Maximum 2D surface height" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DHeight : cudaDeviceAttr = 57 ; # [ doc = "< Maximum 3D surface width" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface3DWidth : cudaDeviceAttr = 58 ; # [ doc = "< Maximum 3D surface height" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface3DHeight : cudaDeviceAttr = 59 ; # [ doc = "< Maximum 3D surface depth" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface3DDepth : cudaDeviceAttr = 60 ; # [ doc = "< Maximum 1D layered surface width" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface1DLayeredWidth : cudaDeviceAttr = 61 ; # [ doc = "< Maximum layers in a 1D layered surface" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface1DLayeredLayers : cudaDeviceAttr = 62 ; # [ doc = "< Maximum 2D layered surface width" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DLayeredWidth : cudaDeviceAttr = 63 ; # [ doc = "< Maximum 2D layered surface height" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DLayeredHeight : cudaDeviceAttr = 64 ; # [ doc = "< Maximum layers in a 2D layered surface" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurface2DLayeredLayers : cudaDeviceAttr = 65 ; # [ doc = "< Maximum cubemap surface width" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurfaceCubemapWidth : cudaDeviceAttr = 66 ; # [ doc = "< Maximum cubemap layered surface width" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurfaceCubemapLayeredWidth : cudaDeviceAttr = 67 ; # [ doc = "< Maximum layers in a cubemap layered surface" ] pub const cudaDeviceAttr_cudaDevAttrMaxSurfaceCubemapLayeredLayers : cudaDeviceAttr = 68 ; # [ doc = "< Maximum 1D linear texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DLinearWidth : cudaDeviceAttr = 69 ; # [ doc = "< Maximum 2D linear texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLinearWidth : cudaDeviceAttr = 70 ; # [ doc = "< Maximum 2D linear texture height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLinearHeight : cudaDeviceAttr = 71 ; # [ doc = "< Maximum 2D linear texture pitch in bytes" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DLinearPitch : cudaDeviceAttr = 72 ; # [ doc = "< Maximum mipmapped 2D texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DMipmappedWidth : cudaDeviceAttr = 73 ; # [ doc = "< Maximum mipmapped 2D texture height" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture2DMipmappedHeight : cudaDeviceAttr = 74 ; # [ doc = "< Major compute capability version number" ] pub const cudaDeviceAttr_cudaDevAttrComputeCapabilityMajor : cudaDeviceAttr = 75 ; # [ doc = "< Minor compute capability version number" ] pub const cudaDeviceAttr_cudaDevAttrComputeCapabilityMinor : cudaDeviceAttr = 76 ; # [ doc = "< Maximum mipmapped 1D texture width" ] pub const cudaDeviceAttr_cudaDevAttrMaxTexture1DMipmappedWidth : cudaDeviceAttr = 77 ; # [ doc = "< Device supports stream priorities" ] pub const cudaDeviceAttr_cudaDevAttrStreamPrioritiesSupported : cudaDeviceAttr = 78 ; # [ doc = "< Device supports caching globals in L1" ] pub const cudaDeviceAttr_cudaDevAttrGlobalL1CacheSupported : cudaDeviceAttr = 79 ; # [ doc = "< Device supports caching locals in L1" ] pub const cudaDeviceAttr_cudaDevAttrLocalL1CacheSupported : cudaDeviceAttr = 80 ; # [ doc = "< Maximum shared memory available per multiprocessor in bytes" ] pub const cudaDeviceAttr_cudaDevAttrMaxSharedMemoryPerMultiprocessor : cudaDeviceAttr = 81 ; # [ doc = "< Maximum number of 32-bit registers available per multiprocessor" ] pub const cudaDeviceAttr_cudaDevAttrMaxRegistersPerMultiprocessor : cudaDeviceAttr = 82 ; # [ doc = "< Device can allocate managed memory on this system" ] pub const cudaDeviceAttr_cudaDevAttrManagedMemory : cudaDeviceAttr = 83 ; # [ doc = "< Device is on a multi-GPU board" ] pub const cudaDeviceAttr_cudaDevAttrIsMultiGpuBoard : cudaDeviceAttr = 84 ; # [ doc = "< Unique identifier for a group of devices on the same multi-GPU board" ] pub const cudaDeviceAttr_cudaDevAttrMultiGpuBoardGroupID : cudaDeviceAttr = 85 ; # [ doc = "< Link between the device and the host supports native atomic operations" ] pub const cudaDeviceAttr_cudaDevAttrHostNativeAtomicSupported : cudaDeviceAttr = 86 ; # [ doc = "< Ratio of single precision performance (in floating-point operations per second) to double precision performance" ] pub const cudaDeviceAttr_cudaDevAttrSingleToDoublePrecisionPerfRatio : cudaDeviceAttr = 87 ; # [ doc = "< Device supports coherently accessing pageable memory without calling cudaHostRegister on it" ] pub const cudaDeviceAttr_cudaDevAttrPageableMemoryAccess : cudaDeviceAttr = 88 ; # [ doc = "< Device can coherently access managed memory concurrently with the CPU" ] pub const cudaDeviceAttr_cudaDevAttrConcurrentManagedAccess : cudaDeviceAttr = 89 ; # [ doc = "< Device supports Compute Preemption" ] pub const cudaDeviceAttr_cudaDevAttrComputePreemptionSupported : cudaDeviceAttr = 90 ; # [ doc = "< Device can access host registered memory at the same virtual address as the CPU" ] pub const cudaDeviceAttr_cudaDevAttrCanUseHostPointerForRegisteredMem : cudaDeviceAttr = 91 ; pub const cudaDeviceAttr_cudaDevAttrReserved92 : cudaDeviceAttr = 92 ; pub const cudaDeviceAttr_cudaDevAttrReserved93 : cudaDeviceAttr = 93 ; pub const cudaDeviceAttr_cudaDevAttrReserved94 : cudaDeviceAttr = 94 ; # [ doc = "< Device supports launching cooperative kernels via ::cudaLaunchCooperativeKernel" ] pub const cudaDeviceAttr_cudaDevAttrCooperativeLaunch : cudaDeviceAttr = 95 ; # [ doc = "< Device can participate in cooperative kernels launched via ::cudaLaunchCooperativeKernelMultiDevice" ] pub const cudaDeviceAttr_cudaDevAttrCooperativeMultiDeviceLaunch : cudaDeviceAttr = 96 ; # [ doc = "< The maximum optin shared memory per block. This value may vary by chip. See ::cudaFuncSetAttribute" ] pub const cudaDeviceAttr_cudaDevAttrMaxSharedMemoryPerBlockOptin : cudaDeviceAttr = 97 ; # [ doc = " CUDA device attributes" ] pub type cudaDeviceAttr = u32 ; # [ doc = " CUDA Error types" ] pub use self :: cudaError as cudaError_t ; # [ doc = " CUDA stream" ] pub type cudaStream_t = * mut CUstream_st ; # [ doc = " CUDA event types" ] pub type cudaEvent_t = * mut CUevent_st ; # [ doc = " CUDA graphics resource types" ] pub type cudaGraphicsResource_t = * mut cudaGraphicsResource ;